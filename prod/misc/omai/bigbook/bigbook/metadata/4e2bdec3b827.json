{
  "id": "4e2bdec3b827",
  "originalPath": "/var/www/orthodox-church-mgmt/orthodoxmetrics/prod/server/scrapers/README.md",
  "relativePath": "server/scrapers/README.md",
  "name": "README.md",
  "extension": ".md",
  "size": 8839,
  "modified": "2025-07-24T14:51:40.448Z",
  "created": "2025-07-24T14:51:40.448Z",
  "classification": {
    "type": "Documentation",
    "category": "Documentation",
    "confidence": 7
  },
  "metadata": {
    "fileStats": {
      "lines": 345,
      "characters": 8811,
      "words": 1008
    },
    "classification": {
      "type": "Documentation",
      "category": "Documentation",
      "confidence": 7
    },
    "dependencies": [],
    "security": {
      "findings": [
        {
          "type": "sensitive_data",
          "pattern": "(?:password|pwd|pass)\\s*[:=]\\s*['\"]([^'\"]+)['\"]",
          "line": 196,
          "redacted": true
        }
      ],
      "hasSecurityIssues": true,
      "redactedContent": "# Orthodox Church Directory Builder\r\n\r\nAn autonomous system for compiling, verifying, and maintaining a comprehensive directory of Orthodox churches in the United States.\r\n\r\n## üéØ Overview\r\n\r\nThis system automatically scrapes church information from various Orthodox jurisdictions, validates the data, and stores it in a structured database. It supports multiple jurisdictions including OCA, GOARCH, Antiochian, ROCOR, Serbian, Romanian, and Bulgarian Orthodox churches.\r\n\r\n## üèóÔ∏è Architecture\r\n\r\n### Core Components\r\n\r\n1. **Main Orchestrator** (`scrapers/index.js`)\r\n   - Coordinates all scraping activities\r\n   - Manages data processing pipeline\r\n   - Handles error logging and statistics\r\n\r\n2. **Jurisdiction Scrapers** (`scrapers/jurisdictions/`)\r\n   - Individual scrapers for each Orthodox jurisdiction\r\n   - Extensible base class for easy addition of new jurisdictions\r\n   - Intelligent content extraction with multiple fallback strategies\r\n\r\n3. **Utility Modules** (`scrapers/utils/`)\r\n   - **URL Validator**: Verifies website accessibility and validity\r\n   - **Data Cleaner**: Standardizes and normalizes church data\r\n   - **Duplicate Detector**: Identifies and resolves duplicate entries\r\n\r\n4. **Database Integration** (`scrapers/database/`)\r\n   - Automated schema management\r\n   - Efficient bulk data operations\r\n   - Comprehensive statistics and reporting\r\n\r\n5. **API Layer** (`routes/church-scraper.js`)\r\n   - RESTful endpoints for church data access\r\n   - Search and filtering capabilities\r\n   - Scraping session management\r\n\r\n## üöÄ Quick Start\r\n\r\n### 1. Database Setup\r\n\r\nFirst, set up the database schema:\r\n\r\n```bash\r\n# Set up database tables and schema\r\nnpm run scraper:setup\r\n\r\n# Verify database connection\r\nnpm run scraper:verify\r\n```\r\n\r\n### 2. Run the Scraper\r\n\r\n```bash\r\n# Full scraping with all features\r\nnpm run scraper:run\r\n\r\n# Quick test run (faster, no URL validation)\r\nnpm run scraper:run-quick\r\n\r\n# Test the scraper system\r\nnpm run scraper:test\r\n```\r\n\r\n### 3. CLI Usage\r\n\r\nThe scraper includes a comprehensive command-line interface:\r\n\r\n```bash\r\n# Basic usage\r\nnode scrapers/cli.js\r\n\r\n# Custom options\r\nnode scrapers/cli.js --output /custom/path --log-level debug --concurrent 5\r\n\r\n# Skip URL validation for faster processing\r\nnode scrapers/cli.js --no-validate-urls\r\n\r\n# Skip duplicate detection\r\nnode scrapers/cli.js --no-duplicate-detection\r\n\r\n# Show help\r\nnode scrapers/cli.js --help\r\n```\r\n\r\n## üìä Database Schema\r\n\r\n### Core Tables\r\n\r\n#### `orthodox_churches`\r\nMain table storing church information:\r\n- Basic info: name, jurisdiction, location\r\n- Contact info: website, email, phone\r\n- Additional metadata: establishment year, clergy\r\n- Search optimization: normalized names, keywords\r\n- Data quality: source tracking, validation status\r\n\r\n#### `scraping_sessions`\r\nTracks scraping activities:\r\n- Session metadata: start/end times, configuration\r\n- Statistics: churches scraped, duplicates found, errors\r\n- Status tracking: running, completed, failed\r\n\r\n#### `scraping_errors`\r\nDetailed error logging:\r\n- Error categorization by jurisdiction and type\r\n- Full error messages and context\r\n- Associated URLs and timestamps\r\n\r\n#### Additional Tables\r\n- `url_validations`: Website validation results\r\n- `duplicate_groups`: Duplicate detection results\r\n\r\n### Views and Procedures\r\n\r\nThe schema includes optimized views for common queries:\r\n- `v_churches_by_jurisdiction`: Summary statistics by jurisdiction\r\n- `v_churches_by_state`: Geographic distribution\r\n- `v_recent_scraping_activity`: Recent scraping sessions\r\n\r\nStored procedures for efficient operations:\r\n- `GetChurchesByJurisdiction(jurisdiction)`\r\n- `GetChurchesByLocation(state, city)`\r\n- `SearchChurches(search_term)`\r\n- `GetScrapingStatistics()`\r\n\r\n## üåê API Endpoints\r\n\r\n### Church Data Access\r\n\r\n```http\r\n# Get all churches with filtering\r\nGET /api/church-scraper/churches?jurisdiction=OCA&state=NY&limit=50\r\n\r\n# Search churches\r\nGET /api/church-scraper/churches/search?q=saint nicholas\r\n\r\n# Get churches by jurisdiction\r\nGET /api/church-scraper/churches/jurisdiction/GOARCH\r\n\r\n# Get statistics\r\nGET /api/church-scraper/statistics\r\n\r\n# Get scraper status\r\nGET /api/church-scraper/status\r\n```\r\n\r\n### Scraping Operations\r\n\r\n```http\r\n# Start new scraping session\r\nPOST /api/church-scraper/scrape\r\nContent-Type: application/json\r\n{\r\n  \"validateUrls\": true,\r\n  \"maxConcurrentScrapers\": 3,\r\n  \"logLevel\": \"info\"\r\n}\r\n\r\n# Get scraping sessions history\r\nGET /api/church-scraper/sessions\r\n```\r\n\r\n## üîß Configuration\r\n\r\n### Environment Variables\r\n\r\n```env\r\n# Database configuration\r\nDB_HOST=localhost\r\nDB_USER=orthodoxapps\r\nDB_PASSWORD=Summerof1982@!\r\nDB_NAME=orthodoxmetrics\r\n\r\n# Optional: Scraper settings\r\nSCRAPER_CONCURRENT_LIMIT=3\r\nSCRAPER_URL_VALIDATION=true\r\nSCRAPER_LOG_LEVEL=info\r\n```\r\n\r\n### Programmatic Configuration\r\n\r\n```javascript\r\nconst ChurchDirectoryBuilder = require('./scrapers/index');\r\n\r\nconst scraper = new ChurchDirectoryBuilder({\r\n    outputDir: '/custom/output',\r\n    logLevel: 'debug',\r\n    maxConcurrentScrapers: 5,\r\n    validateUrls: true,\r\n    enableDuplicateDetection: true,\r\n    saveToDatabase: true,\r\n    databaseConfig: {\r\n        host: 'localhost',\r\n        user: 'orthodoxapps',\r\n        password: '[REDACTED]',\r\n        database: 'orthodoxmetrics'\r\n    }\r\n});\r\n\r\nconst results = await scraper.runAutonomousScraping();\r\n```\r\n\r\n## üìà Monitoring and Statistics\r\n\r\n### Built-in Metrics\r\n\r\nThe system tracks comprehensive metrics:\r\n- **Church Count**: Total churches by jurisdiction and state\r\n- **Data Quality**: Percentage with websites, contact info, full addresses\r\n- **Validation Results**: URL accessibility rates\r\n- **Duplicate Detection**: Duplicate groups and resolution rates\r\n- **Performance**: Scraping duration, success/error rates\r\n\r\n### Example Statistics Output\r\n\r\n```json\r\n{\r\n  \"overall\": {\r\n    \"total_churches\": 2847,\r\n    \"total_jurisdictions\": 7,\r\n    \"churches_with_websites\": 1923,\r\n    \"validated_websites\": 1634,\r\n    \"avg_establishment_year\": 1952\r\n  },\r\n  \"byJurisdiction\": [\r\n    { \"jurisdiction\": \"GOARCH\", \"count\": 1234 },\r\n    { \"jurisdiction\": \"OCA\", \"count\": 678 },\r\n    { \"jurisdiction\": \"Antiochian\", \"count\": 456 }\r\n  ]\r\n}\r\n```\r\n\r\n## üõ†Ô∏è Development\r\n\r\n### Adding New Jurisdictions\r\n\r\n1. Create a new scraper class extending `BaseScraper`:\r\n\r\n```javascript\r\nconst BaseScraper = require('./base-scraper');\r\n\r\nclass NewJurisdictionScraper extends BaseScraper {\r\n    constructor(options = {}) {\r\n        super({\r\n            jurisdiction: 'New Jurisdiction Name',\r\n            baseUrl: 'https://example.org',\r\n            ...options\r\n        });\r\n    }\r\n\r\n    async scrapeChurches() {\r\n        // Implementation specific to this jurisdiction\r\n        const churches = [];\r\n        // ... scraping logic\r\n        return churches;\r\n    }\r\n}\r\n```\r\n\r\n2. Add to the main scraper list in `scrapers/index.js`\r\n3. Test with the jurisdiction-specific test suite\r\n\r\n### Testing\r\n\r\n```bash\r\n# Run comprehensive test\r\nnpm run scraper:test\r\n\r\n# Performance testing\r\nnode scrapers/test-scraper.js --performance\r\n\r\n# Debug mode testing\r\nnode scrapers/test-scraper.js --debug\r\n```\r\n\r\n### Database Management\r\n\r\n```bash\r\n# Reset database (WARNING: Deletes all data)\r\nnpm run scraper:reset\r\n\r\n# Verify connection and show current stats\r\nnpm run scraper:verify\r\n```\r\n\r\n## üîí Data Privacy and Ethics\r\n\r\nThis scraper is designed to:\r\n- Only collect publicly available information\r\n- Respect website robots.txt files\r\n- Implement rate limiting to avoid overloading servers\r\n- Provide clear attribution to data sources\r\n- Support opt-out requests from church administrators\r\n\r\n## üêõ Troubleshooting\r\n\r\n### Common Issues\r\n\r\n1. **Database Connection Errors**\r\n   - Verify database credentials in `.env`\r\n   - Ensure database server is running\r\n   - Check network connectivity\r\n\r\n2. **Scraping Timeouts**\r\n   - Reduce concurrent scrapers: `--concurrent 1`\r\n   - Increase timeout in scraper configuration\r\n   - Check internet connectivity\r\n\r\n3. **Memory Issues**\r\n   - Process churches in smaller batches\r\n   - Disable URL validation for initial runs\r\n   - Monitor memory usage with built-in logging\r\n\r\n### Debug Mode\r\n\r\nEnable detailed logging:\r\n\r\n```bash\r\nnode scrapers/cli.js --log-level debug\r\n```\r\n\r\n### Error Analysis\r\n\r\nReview error logs in the database:\r\n\r\n```sql\r\nSELECT jurisdiction, error_type, COUNT(*) as error_count\r\nFROM scraping_errors \r\nGROUP BY jurisdiction, error_type\r\nORDER BY error_count DESC;\r\n```\r\n\r\n## üìù Contributing\r\n\r\n1. Follow the established patterns for new jurisdiction scrapers\r\n2. Include comprehensive error handling\r\n3. Add appropriate tests for new functionality\r\n4. Update documentation for any API changes\r\n5. Ensure data privacy compliance\r\n\r\n## üìÑ License\r\n\r\nThis project is part of the OrthodoxMetrics system and follows the same licensing terms.\r\n"
    },
    "complexity": {
      "totalLines": 345,
      "codeLines": 194,
      "commentLines": 61,
      "commentRatio": 0.23921568627450981,
      "averageLineLength": 32.85490196078431
    },
    "lastAnalyzed": "2025-07-28T07:20:00.581Z"
  },
  "contentHash": "77b6b8747ec40d0e47ef14c1182366a98e8cb7ec7f6fe6b39c3d371e9a2bf257",
  "discoveredAt": "2025-07-28T07:20:00.581Z"
}