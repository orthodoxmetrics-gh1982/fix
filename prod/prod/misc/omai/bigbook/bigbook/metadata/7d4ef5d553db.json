{
  "id": "7d4ef5d553db",
  "originalPath": "/var/www/orthodox-church-mgmt/orthodoxmetrics/prod/server/services/ai/autoLearningTaskService.js",
  "relativePath": "server/services/ai/autoLearningTaskService.js",
  "name": "autoLearningTaskService.js",
  "extension": ".js",
  "size": 32483,
  "modified": "2025-07-19T13:15:21.801Z",
  "created": "2025-07-15T05:55:49.131Z",
  "classification": {
    "type": "Server Scripts",
    "category": "Backend > Server",
    "confidence": 3
  },
  "metadata": {
    "fileStats": {
      "lines": 1050,
      "characters": 32435,
      "words": 2905
    },
    "classification": {
      "type": "Server Scripts",
      "category": "Backend > Server",
      "confidence": 3
    },
    "dependencies": [
      {
        "type": "npm_package",
        "name": "fs",
        "line": 5
      },
      {
        "type": "npm_package",
        "name": "path",
        "line": 6
      },
      {
        "type": "npm_package",
        "name": "@google-cloud/vision",
        "line": 353
      },
      {
        "type": "npm_package",
        "name": "tesseract.js",
        "line": 439
      }
    ],
    "security": {
      "findings": [
        {
          "type": "sensitive_data",
          "pattern": "process\\.env\\.([A-Z_]+)",
          "line": 304,
          "redacted": true
        }
      ],
      "hasSecurityIssues": true,
      "redactedContent": "// server/services/ai/autoLearningTaskService.js\r\n// 24-Hour Auto-Learning OCR Task Service\r\n// Processes all available record images to improve OCR mapping and field recognition\r\n\r\nconst fs = require('fs').promises;\r\nconst path = require('path');\r\nconst { promisePool: db } = require('../../config/db');\r\nconst { switchToDatabase } = require('../../utils/dbSwitcher');\r\nconst logger = require('../../utils/logger');\r\n\r\nclass AutoLearningTaskService {\r\n  constructor() {\r\n    this.isRunning = false;\r\n    this.startTime = null;\r\n    this.endTime = null;\r\n    this.stats = {\r\n      recordsProcessed: 0,\r\n      successRate: 0,\r\n      averageConfidence: 0,\r\n      errorCount: 0,\r\n      mostFailedFields: [],\r\n      lastImage: '',\r\n      timeRemaining: '',\r\n      totalRecords: 0,\r\n      completed: 0,\r\n      errors: 0,\r\n      trainingRulesGenerated: 0\r\n    };\r\n    this.processingErrors = [];\r\n    this.learningRules = new Map();\r\n    this.maxHours = 24;\r\n    this.batchSize = 10; // Process 10 images at a time\r\n  }\r\n\r\n  /**\r\n   * Start the auto-learning task\r\n   * @param {string} basePath - Base directory path for record images\r\n   * @param {number} hours - Maximum hours to run (default: 24)\r\n   */\r\n  async startTask(basePath = 'data/records/', hours = 24) {\r\n    if (this.isRunning) {\r\n      throw new Error('Auto-learning task is already running');\r\n    }\r\n\r\n    this.isRunning = true;\r\n    this.startTime = new Date();\r\n    this.maxHours = hours;\r\n    this.endTime = new Date(this.startTime.getTime() + (hours * 60 * 60 * 1000));\r\n\r\n    logger.info('AutoLearningTask', 'Starting 24h auto-learning OCR task', {\r\n      basePath,\r\n      maxHours: hours,\r\n      startTime: this.startTime,\r\n      endTime: this.endTime\r\n    });\r\n\r\n    try {\r\n      // Initialize processing directories\r\n      await this.initializeDirectories();\r\n      \r\n      // Discover all images in record directories\r\n      const imageFiles = await this.discoverImages(basePath);\r\n      this.stats.totalRecords = imageFiles.length;\r\n\r\n      logger.info('AutoLearningTask', `Discovered ${imageFiles.length} images to process`);\r\n\r\n      // Process images in batches\r\n      await this.processImageBatches(imageFiles);\r\n\r\n      // Generate final summary\r\n      await this.generateFinalSummary();\r\n\r\n    } catch (error) {\r\n      logger.error('AutoLearningTask', 'Error in auto-learning task', { error: error.message });\r\n      this.processingErrors.push({\r\n        type: 'task_error',\r\n        message: error.message,\r\n        timestamp: new Date(),\r\n        stack: error.stack\r\n      });\r\n    } finally {\r\n      this.isRunning = false;\r\n      logger.info('AutoLearningTask', 'Auto-learning task completed', {\r\n        duration: new Date() - this.startTime,\r\n        stats: this.stats\r\n      });\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Stop the running task\r\n   */\r\n  async stopTask() {\r\n    if (!this.isRunning) {\r\n      return false;\r\n    }\r\n\r\n    this.isRunning = false;\r\n    logger.info('AutoLearningTask', 'Auto-learning task stopped by user');\r\n    await this.generateFinalSummary();\r\n    return true;\r\n  }\r\n\r\n  /**\r\n   * Get current task status\r\n   */\r\n  getStatus() {\r\n    if (!this.isRunning && this.startTime) {\r\n      // Task completed\r\n      return {\r\n        ...this.stats,\r\n        status: 'completed',\r\n        duration: new Date() - this.startTime,\r\n        isRunning: false\r\n      };\r\n    }\r\n\r\n    if (this.isRunning) {\r\n      const now = new Date();\r\n      const elapsed = now - this.startTime;\r\n      const remaining = Math.max(0, this.endTime - now);\r\n      \r\n      this.stats.timeRemaining = this.formatDuration(remaining);\r\n      \r\n      return {\r\n        ...this.stats,\r\n        status: 'running',\r\n        elapsed: this.formatDuration(elapsed),\r\n        isRunning: true,\r\n        progress: this.stats.totalRecords > 0 ? \r\n          Math.round((this.stats.recordsProcessed / this.stats.totalRecords) * 100) : 0\r\n      };\r\n    }\r\n\r\n    return {\r\n      status: 'idle',\r\n      isRunning: false,\r\n      stats: this.stats\r\n    };\r\n  }\r\n\r\n  /**\r\n   * Initialize required directories\r\n   */\r\n  async initializeDirectories() {\r\n    const dirs = [\r\n      '/processed_data',\r\n      '/logs',\r\n      '/ai/learning'\r\n    ];\r\n\r\n    for (const dir of dirs) {\r\n      try {\r\n        await fs.mkdir(path.join(process.cwd(), dir), { recursive: true });\r\n      } catch (error) {\r\n        if (error.code !== 'EEXIST') {\r\n          throw error;\r\n        }\r\n      }\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Discover all images in record directories\r\n   */\r\n  async discoverImages(basePath) {\r\n    const recordTypes = ['baptism', 'marriage', 'funeral'];\r\n    const imageExtensions = ['.jpg', '.jpeg', '.png', '.tiff', '.pdf'];\r\n    const images = [];\r\n\r\n    // Resolve the base path relative to the project root\r\n    const fullBasePath = path.resolve(process.cwd(), basePath);\r\n    \r\n    logger.info('AutoLearningTask', `Searching for images in: ${fullBasePath}`);\r\n\r\n    for (const recordType of recordTypes) {\r\n      const recordPath = path.join(fullBasePath, recordType);\r\n      \r\n      try {\r\n        await fs.access(recordPath);\r\n        const files = await fs.readdir(recordPath);\r\n        \r\n        logger.info('AutoLearningTask', `Found ${files.length} files in ${recordType} directory`);\r\n        \r\n        for (const file of files) {\r\n          const ext = path.extname(file).toLowerCase();\r\n          if (imageExtensions.includes(ext)) {\r\n            images.push({\r\n              path: path.join(recordPath, file),\r\n              filename: file,\r\n              recordType,\r\n              extension: ext\r\n            });\r\n          }\r\n        }\r\n      } catch (error) {\r\n        logger.warn('AutoLearningTask', `Skipping directory ${recordPath}: ${error.message}`);\r\n      }\r\n    }\r\n\r\n    logger.info('AutoLearningTask', `Total images discovered: ${images.length}`);\r\n    return images;\r\n  }\r\n\r\n  /**\r\n   * Process images in batches\r\n   */\r\n  async processImageBatches(imageFiles) {\r\n    for (let i = 0; i < imageFiles.length && this.isRunning; i += this.batchSize) {\r\n      // Check time limit\r\n      if (new Date() >= this.endTime) {\r\n        logger.info('AutoLearningTask', 'Time limit reached, stopping processing');\r\n        break;\r\n      }\r\n\r\n      const batch = imageFiles.slice(i, i + this.batchSize);\r\n      await this.processBatch(batch);\r\n\r\n      // Small delay between batches to prevent overwhelming the system\r\n      await new Promise(resolve => setTimeout(resolve, 1000));\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Process a batch of images\r\n   */\r\n  async processBatch(batch) {\r\n    const promises = batch.map(image => this.processImage(image));\r\n    await Promise.allSettled(promises);\r\n  }\r\n\r\n  /**\r\n   * Process a single image\r\n   */\r\n  async processImage(image) {\r\n    try {\r\n      this.stats.lastImage = image.filename;\r\n      logger.info('AutoLearningTask', `Processing image: ${image.filename}`);\r\n\r\n      // 1. Apply preprocessing pipeline\r\n      const preprocessedImage = await this.preprocessImage(image);\r\n\r\n      // 2. Run OCR with both Tesseract and Google Vision\r\n      const ocrResults = await this.runOcrProcessing(preprocessedImage);\r\n\r\n      // 3. Map fields using existing field mapper\r\n      const mappedFields = await this.mapFields(ocrResults, image.recordType);\r\n\r\n      // 4. Analyze confidence and compare with existing records\r\n      const analysis = await this.analyzeResults(mappedFields, image);\r\n\r\n      // 5. Store results and learning data\r\n      await this.storeResults(image, ocrResults, mappedFields, analysis);\r\n\r\n      // 6. Generate learning rules if corrections exist\r\n      await this.generateLearningRules(image, mappedFields, analysis);\r\n\r\n      this.stats.recordsProcessed++;\r\n      this.updateSuccessRate();\r\n\r\n    } catch (error) {\r\n      this.stats.errorCount++;\r\n      this.processingErrors.push({\r\n        type: 'image_processing_error',\r\n        filename: image.filename,\r\n        message: error.message,\r\n        timestamp: new Date()\r\n      });\r\n      \r\n      logger.error('AutoLearningTask', `Error processing ${image.filename}`, { error: error.message });\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Apply preprocessing pipeline to image\r\n   */\r\n  async preprocessImage(image) {\r\n    // TODO: Implement image preprocessing\r\n    // - Grayscale conversion\r\n    // - Thresholding\r\n    // - Denoising\r\n    // - Deskewing\r\n    // - Cropping\r\n    \r\n    return {\r\n      ...image,\r\n      preprocessed: true,\r\n      preprocessingSteps: ['grayscale', 'threshold', 'denoise', 'deskew', 'crop']\r\n    };\r\n  }\r\n\r\n  /**\r\n   * Run OCR processing with multiple engines\r\n   */\r\n  async runOcrProcessing(image) {\r\n    const results = {\r\n      tesseract: null,\r\n      googleVision: null,\r\n      timestamp: new Date()\r\n    };\r\n\r\n    try {\r\n      // Switch to OCR database\r\n      await switchToDatabase(process.env.[REDACTED] || 'orthodoxmetrics_ocr_db');\r\n\r\n      // Create OCR job for Google Vision processing\r\n      const [jobResult] = await db.query(`\r\n        INSERT INTO ocr_jobs (\r\n          filename, \r\n          file_path, \r\n          record_type,\r\n          status,\r\n          church_id,\r\n          created_at,\r\n          auto_learning,\r\n          batch_id,\r\n          ocr_engine\r\n        ) VALUES (?, ?, ?, 'pending', 14, NOW(), 1, ?, 'hybrid')\r\n      `, [\r\n        image.filename,\r\n        image.path,\r\n        image.recordType,\r\n        `auto_learning_${Date.now()}`\r\n      ]);\r\n\r\n      const jobId = jobResult.insertId;\r\n\r\n      // Process with Google Vision API\r\n      results.googleVision = await this.processWithGoogleVision(image, jobId);\r\n      \r\n      // Process with Tesseract for comparison\r\n      results.tesseract = await this.processWithTesseract(image);\r\n\r\n      logger.info('AutoLearningTask', `Completed dual OCR processing for ${image.filename}`, {\r\n        jobId,\r\n        googleVisionConfidence: results.googleVision?.confidence,\r\n        tesseractConfidence: results.tesseract?.confidence,\r\n        tesseractSimulated: results.tesseract?.simulated || false\r\n      });\r\n\r\n    } catch (error) {\r\n      logger.error('AutoLearningTask', `OCR processing failed for ${image.filename}`, { error: error.message });\r\n    }\r\n\r\n    return results;\r\n  }\r\n\r\n  /**\r\n   * Process image with Google Vision API\r\n   */\r\n  async processWithGoogleVision(image, jobId) {\r\n    try {\r\n      const vision = require('@google-cloud/vision');\r\n      const client = new vision.ImageAnnotatorClient();\r\n\r\n      // Read the image file\r\n      const imageBuffer = await fs.readFile(image.path);\r\n\r\n      // Configure the request\r\n      const request = {\r\n        image: { content: imageBuffer },\r\n        features: [\r\n          { type: 'TEXT_DETECTION' },\r\n          { type: 'DOCUMENT_TEXT_DETECTION' }\r\n        ],\r\n        imageContext: {\r\n          languageHints: ['en', 'el'] // English and Greek for Orthodox records\r\n        }\r\n      };\r\n\r\n      // Perform OCR\r\n      const [result] = await client.annotateImage(request);\r\n      \r\n      const detections = result.textAnnotations;\r\n      const fullText = result.fullTextAnnotation;\r\n\r\n      if (detections && detections.length > 0) {\r\n        // Calculate confidence from detection scores\r\n        const confidenceSum = detections.slice(1).reduce((sum, detection) => {\r\n          return sum + (detection.confidence || 0.8); // Default confidence if not provided\r\n        }, 0);\r\n        const avgConfidence = confidenceSum / Math.max(1, detections.length - 1);\r\n\r\n        // Update OCR job status\r\n        await db.query(`\r\n          UPDATE ocr_jobs \r\n          SET status = 'completed',\r\n              extracted_text = ?,\r\n              confidence_score = ?,\r\n              completed_at = NOW()\r\n          WHERE id = ?\r\n        `, [\r\n          detections[0].description,\r\n          avgConfidence,\r\n          jobId\r\n        ]);\r\n\r\n        return {\r\n          jobId,\r\n          extractedText: detections[0].description,\r\n          confidence: avgConfidence,\r\n          fullTextAnnotation: fullText,\r\n          detections: detections.slice(1, 6), // First 5 individual detections\r\n          engine: 'google_vision'\r\n        };\r\n      } else {\r\n        throw new Error('No text detected by Google Vision');\r\n      }\r\n\r\n    } catch (error) {\r\n      logger.error('AutoLearningTask', `Google Vision processing failed for ${image.filename}`, { error: error.message });\r\n      \r\n      // Update job status as failed\r\n      if (jobId) {\r\n        await db.query(`\r\n          UPDATE ocr_jobs \r\n          SET status = 'failed',\r\n              error_message = ?,\r\n              completed_at = NOW()\r\n          WHERE id = ?\r\n        `, [error.message, jobId]);\r\n      }\r\n\r\n      return {\r\n        jobId,\r\n        extractedText: '',\r\n        confidence: 0,\r\n        error: error.message,\r\n        engine: 'google_vision'\r\n      };\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Process image with Tesseract (fallback/comparison)\r\n   */\r\n  async processWithTesseract(image) {\r\n    try {\r\n      const { createWorker } = require('tesseract.js');\r\n      \r\n      logger.info('AutoLearningTask', `Processing ${image.filename} with Tesseract OCR`);\r\n      \r\n      // Create a new Tesseract worker\r\n      const worker = await createWorker('eng+ell', 1, {\r\n        logger: m => {\r\n          if (m.status === 'recognizing text') {\r\n            logger.debug('AutoLearningTask', `Tesseract progress: ${Math.round(m.progress * 100)}%`);\r\n          }\r\n        }\r\n      });\r\n\r\n      try {\r\n        // Configure Tesseract for better Orthodox church record recognition\r\n        await worker.setParameters({\r\n          tessedit_char_whitelist: 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789.,;:()/-+ ΑΒΓΔΕΖΗΘΙΚΛΜΝΞΟΠΡΣΤΥΦΧΨΩαβγδεζηθικλμνξοπρστυφχψω',\r\n          tessedit_pageseg_mode: '6', // Uniform block of text\r\n          preserve_interword_spaces: '1'\r\n        });\r\n\r\n        // Perform OCR recognition\r\n        const { data: { text, confidence, words } } = await worker.recognize(image.path);\r\n        \r\n        // Calculate word-level confidence average\r\n        let wordConfidenceSum = 0;\r\n        let validWords = 0;\r\n        \r\n        if (words && words.length > 0) {\r\n          words.forEach(word => {\r\n            if (word.confidence > 0) {\r\n              wordConfidenceSum += word.confidence;\r\n              validWords++;\r\n            }\r\n          });\r\n        }\r\n        \r\n        const avgConfidence = validWords > 0 ? wordConfidenceSum / validWords / 100 : confidence / 100;\r\n        \r\n        logger.info('AutoLearningTask', `Tesseract completed for ${image.filename}`, {\r\n          textLength: text.length,\r\n          confidence: avgConfidence,\r\n          wordCount: validWords\r\n        });\r\n\r\n        return {\r\n          extractedText: text.trim(),\r\n          confidence: Math.max(0, Math.min(1, avgConfidence)), // Ensure 0-1 range\r\n          wordCount: validWords,\r\n          words: words?.slice(0, 10), // First 10 words for analysis\r\n          engine: 'tesseract',\r\n          simulated: false\r\n        };\r\n\r\n      } finally {\r\n        // Always terminate the worker to free resources\r\n        await worker.terminate();\r\n      }\r\n\r\n    } catch (error) {\r\n      logger.error('AutoLearningTask', `Tesseract processing failed for ${image.filename}`, { error: error.message });\r\n      \r\n      return {\r\n        extractedText: '',\r\n        confidence: 0,\r\n        error: error.message,\r\n        engine: 'tesseract',\r\n        simulated: false\r\n      };\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Map OCR results to database fields\r\n   */\r\n  async mapFields(ocrResults, recordType) {\r\n    try {\r\n      // Get the best OCR result (prefer Google Vision, fallback to Tesseract)\r\n      const primaryOcrResult = ocrResults.googleVision?.extractedText ? \r\n        ocrResults.googleVision : ocrResults.tesseract;\r\n      \r\n      if (!primaryOcrResult?.extractedText) {\r\n        throw new Error('No OCR text available for field mapping');\r\n      }\r\n\r\n      const extractedText = primaryOcrResult.extractedText;\r\n      const baseConfidence = primaryOcrResult.confidence || 0.5;\r\n\r\n      // Initialize field mapping result\r\n      const mappedFields = {\r\n        mapped: true,\r\n        recordType,\r\n        primaryEngine: primaryOcrResult.engine,\r\n        fields: {}\r\n      };\r\n\r\n      // Define field patterns for each record type\r\n      const fieldPatterns = this.getFieldPatternsForRecordType(recordType);\r\n\r\n      // Extract fields using pattern matching\r\n      for (const [fieldName, pattern] of Object.entries(fieldPatterns)) {\r\n        const fieldResult = this.extractFieldFromText(extractedText, pattern, baseConfidence);\r\n        if (fieldResult.value) {\r\n          mappedFields.fields[fieldName] = fieldResult;\r\n        }\r\n      }\r\n\r\n      // Compare results between OCR engines if both available\r\n      if (ocrResults.googleVision && ocrResults.tesseract) {\r\n        mappedFields.engineComparison = this.compareOcrResults(\r\n          ocrResults.googleVision, \r\n          ocrResults.tesseract\r\n        );\r\n      }\r\n\r\n      return mappedFields;\r\n\r\n    } catch (error) {\r\n      logger.error('AutoLearningTask', `Field mapping failed`, { error: error.message });\r\n      \r\n      return {\r\n        mapped: false,\r\n        recordType,\r\n        error: error.message,\r\n        fields: {}\r\n      };\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Get field patterns for specific record type\r\n   */\r\n  getFieldPatternsForRecordType(recordType) {\r\n    const commonPatterns = {\r\n      'full_name': /([A-Z][a-z]+\\s+[A-Z][a-z]+(?:\\s+[A-Z][a-z]+)?)/g,\r\n      'date': /(\\d{1,2}[\\/\\-]\\d{1,2}[\\/\\-]\\d{2,4})|(\\w+\\s+\\d{1,2},?\\s+\\d{4})/g,\r\n      'location': /([\\w\\s]+(?:Church|Parish|Cathedral|Chapel))/gi,\r\n      'clergy': /((?:Father|Fr\\.|Priest|Archpriest|Deacon|Bishop)\\s+[A-Z][a-z]+(?:\\s+[A-Z][a-z]+)?)/gi\r\n    };\r\n\r\n    switch (recordType) {\r\n      case 'baptism':\r\n        return {\r\n          ...commonPatterns,\r\n          'birth_date': /(?:born|birth)[\\s:]*(\\d{1,2}[\\/\\-]\\d{1,2}[\\/\\-]\\d{2,4})/gi,\r\n          'baptism_date': /(?:baptized|baptism)[\\s:]*(\\d{1,2}[\\/\\-]\\d{1,2}[\\/\\-]\\d{2,4})/gi,\r\n          'parents': /(?:parents|father|mother)[\\s:]*([A-Z][a-z]+\\s+[A-Z][a-z]+)/gi\r\n        };\r\n      \r\n      case 'marriage':\r\n        return {\r\n          ...commonPatterns,\r\n          'bride_name': /(?:bride|wife)[\\s:]*([A-Z][a-z]+\\s+[A-Z][a-z]+)/gi,\r\n          'groom_name': /(?:groom|husband)[\\s:]*([A-Z][a-z]+\\s+[A-Z][a-z]+)/gi,\r\n          'marriage_date': /(?:married|marriage|wedding)[\\s:]*(\\d{1,2}[\\/\\-]\\d{1,2}[\\/\\-]\\d{2,4})/gi,\r\n          'witnesses': /(?:witnesses?)[\\s:]*([A-Z][a-z]+\\s+[A-Z][a-z]+)/gi\r\n        };\r\n      \r\n      case 'funeral':\r\n        return {\r\n          ...commonPatterns,\r\n          'death_date': /(?:died|death|deceased)[\\s:]*(\\d{1,2}[\\/\\-]\\d{1,2}[\\/\\-]\\d{2,4})/gi,\r\n          'funeral_date': /(?:funeral|burial|service)[\\s:]*(\\d{1,2}[\\/\\-]\\d{1,2}[\\/\\-]\\d{2,4})/gi,\r\n          'age': /(?:age|aged)[\\s:]*(\\d{1,3})/gi\r\n        };\r\n      \r\n      default:\r\n        return commonPatterns;\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Extract field value from text using pattern\r\n   */\r\n  extractFieldFromText(text, pattern, baseConfidence) {\r\n    const matches = text.match(pattern);\r\n    \r\n    if (matches && matches.length > 0) {\r\n      // Use the first match, clean it up\r\n      const value = matches[0].trim();\r\n      \r\n      // Calculate confidence based on pattern strength and base confidence\r\n      const patternConfidence = matches.length > 1 ? 0.9 : 0.7; // Higher if multiple matches\r\n      const finalConfidence = Math.min(baseConfidence * patternConfidence, 0.95);\r\n      \r\n      return {\r\n        value,\r\n        confidence: finalConfidence,\r\n        matches: matches.length,\r\n        pattern: pattern.source\r\n      };\r\n    }\r\n    \r\n    return {\r\n      value: null,\r\n      confidence: 0,\r\n      matches: 0,\r\n      pattern: pattern.source\r\n    };\r\n  }\r\n\r\n  /**\r\n   * Compare OCR results between engines\r\n   */\r\n  compareOcrResults(googleVision, tesseract) {\r\n    return {\r\n      textSimilarity: this.calculateTextSimilarity(\r\n        googleVision.extractedText, \r\n        tesseract.extractedText\r\n      ),\r\n      confidenceDifference: Math.abs(googleVision.confidence - tesseract.confidence),\r\n      recommendedEngine: googleVision.confidence > tesseract.confidence ? 'google_vision' : 'tesseract',\r\n      agreement: googleVision.extractedText === tesseract.extractedText\r\n    };\r\n  }\r\n\r\n  /**\r\n   * Calculate text similarity between two strings\r\n   */\r\n  calculateTextSimilarity(text1, text2) {\r\n    if (text1 === text2) return 1.0;\r\n    \r\n    const longer = text1.length > text2.length ? text1 : text2;\r\n    const shorter = text1.length > text2.length ? text2 : text1;\r\n    \r\n    if (longer.length === 0) return 1.0;\r\n    \r\n    const editDistance = this.levenshteinDistance(longer, shorter);\r\n    return (longer.length - editDistance) / longer.length;\r\n  }\r\n\r\n  /**\r\n   * Calculate Levenshtein distance between two strings\r\n   */\r\n  levenshteinDistance(str1, str2) {\r\n    const matrix = [];\r\n    \r\n    for (let i = 0; i <= str2.length; i++) {\r\n      matrix[i] = [i];\r\n    }\r\n    \r\n    for (let j = 0; j <= str1.length; j++) {\r\n      matrix[0][j] = j;\r\n    }\r\n    \r\n    for (let i = 1; i <= str2.length; i++) {\r\n      for (let j = 1; j <= str1.length; j++) {\r\n        if (str2.charAt(i - 1) === str1.charAt(j - 1)) {\r\n          matrix[i][j] = matrix[i - 1][j - 1];\r\n        } else {\r\n          matrix[i][j] = Math.min(\r\n            matrix[i - 1][j - 1] + 1,\r\n            matrix[i][j - 1] + 1,\r\n            matrix[i - 1][j] + 1\r\n          );\r\n        }\r\n      }\r\n    }\r\n    \r\n    return matrix[str2.length][str1.length];\r\n  }\r\n\r\n  /**\r\n   * Analyze results and compare with existing records\r\n   */\r\n  async analyzeResults(mappedFields, image) {\r\n    const analysis = {\r\n      averageConfidence: 0,\r\n      lowConfidenceFields: [],\r\n      potentialMatches: [],\r\n      hasErrors: false\r\n    };\r\n\r\n    // Calculate average confidence\r\n    const confidences = Object.values(mappedFields.fields || {})\r\n      .map(field => field.confidence || 0);\r\n    \r\n    if (confidences.length > 0) {\r\n      analysis.averageConfidence = confidences.reduce((a, b) => a + b, 0) / confidences.length;\r\n    }\r\n\r\n    // Identify low confidence fields\r\n    analysis.lowConfidenceFields = Object.entries(mappedFields.fields || {})\r\n      .filter(([, field]) => field.confidence < 0.7)\r\n      .map(([fieldName]) => fieldName);\r\n\r\n    this.updateAverageConfidence(analysis.averageConfidence);\r\n    \r\n    return analysis;\r\n  }\r\n\r\n  /**\r\n   * Store processing results\r\n   */\r\n  async storeResults(image, ocrResults, mappedFields, analysis) {\r\n    const results = {\r\n      filename: image.filename,\r\n      recordType: image.recordType,\r\n      ocrResults,\r\n      mappedFields,\r\n      analysis,\r\n      timestamp: new Date()\r\n    };\r\n\r\n    // Write to processed_data/ocr_results.json\r\n    const resultsPath = path.join(process.cwd(), 'processed_data', 'ocr_results.json');\r\n    \r\n    try {\r\n      let existingResults = [];\r\n      try {\r\n        const data = await fs.readFile(resultsPath, 'utf8');\r\n        existingResults = JSON.parse(data);\r\n      } catch (error) {\r\n        // File doesn't exist yet, start with empty array\r\n      }\r\n\r\n      existingResults.push(results);\r\n      await fs.writeFile(resultsPath, JSON.stringify(existingResults, null, 2));\r\n      \r\n    } catch (error) {\r\n      logger.error('AutoLearningTask', `Failed to store results for ${image.filename}`, { error: error.message });\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Generate learning rules from corrections\r\n   */\r\n  async generateLearningRules(image, mappedFields, analysis) {\r\n    try {\r\n      // Generate rules for low confidence fields\r\n      if (analysis.lowConfidenceFields.length > 0) {\r\n        for (const fieldName of analysis.lowConfidenceFields) {\r\n          await this.createFieldImprovementRule(fieldName, mappedFields, image);\r\n        }\r\n      }\r\n\r\n      // Generate rules for OCR engine comparison\r\n      if (mappedFields.engineComparison) {\r\n        await this.createEngineComparisonRule(mappedFields.engineComparison, image);\r\n      }\r\n\r\n      // Generate pattern-based rules\r\n      await this.createPatternBasedRules(mappedFields, image);\r\n\r\n      // Store learning rules to file\r\n      await this.storeLearningRules();\r\n\r\n    } catch (error) {\r\n      logger.error('AutoLearningTask', `Learning rule generation failed for ${image.filename}`, { \r\n        error: error.message \r\n      });\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Create improvement rule for low confidence field\r\n   */\r\n  async createFieldImprovementRule(fieldName, mappedFields, image) {\r\n    this.stats.trainingRulesGenerated++;\r\n\r\n    const field = mappedFields.fields[fieldName];\r\n    const ruleId = `field_improvement_${this.stats.trainingRulesGenerated}`;\r\n\r\n    const rule = {\r\n      id: ruleId,\r\n      type: 'field_improvement',\r\n      field: fieldName,\r\n      pattern: field?.pattern || 'unknown',\r\n      issue: 'low_confidence',\r\n      currentConfidence: field?.confidence || 0,\r\n      suggestion: this.generateFieldSuggestion(fieldName, field),\r\n      recordType: image.recordType,\r\n      imageExtension: image.extension,\r\n      frequency: 1,\r\n      timestamp: new Date()\r\n    };\r\n\r\n    this.learningRules.set(ruleId, rule);\r\n    \r\n    logger.info('AutoLearningTask', `Generated field improvement rule for ${fieldName}`, {\r\n      ruleId,\r\n      confidence: field?.confidence\r\n    });\r\n  }\r\n\r\n  /**\r\n   * Create rule based on OCR engine comparison\r\n   */\r\n  async createEngineComparisonRule(comparison, image) {\r\n    if (comparison.confidenceDifference > 0.2) { // Significant difference\r\n      this.stats.trainingRulesGenerated++;\r\n\r\n      const ruleId = `engine_comparison_${this.stats.trainingRulesGenerated}`;\r\n      \r\n      const rule = {\r\n        id: ruleId,\r\n        type: 'engine_comparison',\r\n        issue: 'engine_disagreement',\r\n        textSimilarity: comparison.textSimilarity,\r\n        confidenceDifference: comparison.confidenceDifference,\r\n        recommendedEngine: comparison.recommendedEngine,\r\n        suggestion: comparison.textSimilarity < 0.5 ? \r\n          'Consider image preprocessing' : \r\n          `Prefer ${comparison.recommendedEngine} for similar images`,\r\n        recordType: image.recordType,\r\n        imageExtension: image.extension,\r\n        timestamp: new Date()\r\n      };\r\n\r\n      this.learningRules.set(ruleId, rule);\r\n      \r\n      logger.info('AutoLearningTask', `Generated engine comparison rule`, {\r\n        ruleId,\r\n        similarity: comparison.textSimilarity,\r\n        recommended: comparison.recommendedEngine\r\n      });\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Create pattern-based learning rules\r\n   */\r\n  async createPatternBasedRules(mappedFields, image) {\r\n    // Generate rules for successful pattern matches\r\n    for (const [fieldName, field] of Object.entries(mappedFields.fields)) {\r\n      if (field.confidence > 0.8 && field.matches > 0) {\r\n        const existingRule = Array.from(this.learningRules.values()).find(\r\n          rule => rule.type === 'pattern_success' && \r\n                  rule.field === fieldName && \r\n                  rule.pattern === field.pattern\r\n        );\r\n\r\n        if (existingRule) {\r\n          // Update existing rule frequency\r\n          existingRule.frequency++;\r\n          existingRule.averageConfidence = (\r\n            (existingRule.averageConfidence * (existingRule.frequency - 1)) + field.confidence\r\n          ) / existingRule.frequency;\r\n        } else {\r\n          // Create new pattern success rule\r\n          this.stats.trainingRulesGenerated++;\r\n          const ruleId = `pattern_success_${this.stats.trainingRulesGenerated}`;\r\n\r\n          const rule = {\r\n            id: ruleId,\r\n            type: 'pattern_success',\r\n            field: fieldName,\r\n            pattern: field.pattern,\r\n            averageConfidence: field.confidence,\r\n            frequency: 1,\r\n            recordType: image.recordType,\r\n            suggestion: `Pattern works well for ${fieldName} in ${image.recordType} records`,\r\n            timestamp: new Date()\r\n          };\r\n\r\n          this.learningRules.set(ruleId, rule);\r\n        }\r\n      }\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Generate suggestion for field improvement\r\n   */\r\n  generateFieldSuggestion(fieldName, field) {\r\n    if (!field || field.confidence < 0.3) {\r\n      return `Consider alternative pattern for ${fieldName} extraction`;\r\n    } else if (field.confidence < 0.5) {\r\n      return `Improve preprocessing for ${fieldName} field clarity`;\r\n    } else if (field.confidence < 0.7) {\r\n      return `Refine pattern matching for ${fieldName}`;\r\n    } else {\r\n      return `Monitor ${fieldName} extraction patterns`;\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Store learning rules to file\r\n   */\r\n  async storeLearningRules() {\r\n    try {\r\n      const rulesData = {\r\n        version: '1.0.0',\r\n        generatedAt: new Date().toISOString(),\r\n        totalRules: this.learningRules.size,\r\n        rules: Array.from(this.learningRules.values()),\r\n        categories: this.categorizeLearningRules()\r\n      };\r\n\r\n      const rulesPath = path.join(process.cwd(), 'ai', 'learning', 'mappings.json');\r\n      \r\n      // Ensure directory exists\r\n      await fs.mkdir(path.dirname(rulesPath), { recursive: true });\r\n      \r\n      await fs.writeFile(rulesPath, JSON.stringify(rulesData, null, 2));\r\n      \r\n      logger.info('AutoLearningTask', `Learning rules stored to ${rulesPath}`, {\r\n        totalRules: this.learningRules.size\r\n      });\r\n\r\n    } catch (error) {\r\n      logger.error('AutoLearningTask', `Failed to store learning rules`, { \r\n        error: error.message \r\n      });\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Categorize learning rules by type\r\n   */\r\n  categorizeLearningRules() {\r\n    const categories = {\r\n      fieldImprovements: [],\r\n      engineComparisons: [],\r\n      patternSuccesses: [],\r\n      other: []\r\n    };\r\n\r\n    for (const rule of this.learningRules.values()) {\r\n      switch (rule.type) {\r\n        case 'field_improvement':\r\n          categories.fieldImprovements.push(rule);\r\n          break;\r\n        case 'engine_comparison':\r\n          categories.engineComparisons.push(rule);\r\n          break;\r\n        case 'pattern_success':\r\n          categories.patternSuccesses.push(rule);\r\n          break;\r\n        default:\r\n          categories.other.push(rule);\r\n      }\r\n    }\r\n\r\n    return categories;\r\n  }\r\n\r\n  /**\r\n   * Generate final summary report\r\n   */\r\n  async generateFinalSummary() {\r\n    const summary = {\r\n      totalRecords: this.stats.totalRecords,\r\n      completed: this.stats.recordsProcessed,\r\n      errors: this.stats.errorCount,\r\n      runtime: this.formatDuration(new Date() - this.startTime),\r\n      trainingRulesGenerated: this.stats.trainingRulesGenerated,\r\n      averageConfidence: this.stats.averageConfidence,\r\n      successRate: this.stats.successRate,\r\n      learningRules: Array.from(this.learningRules.values()),\r\n      errors: this.processingErrors,\r\n      timestamp: new Date()\r\n    };\r\n\r\n    const summaryPath = path.join(\r\n      process.cwd(), \r\n      'logs', \r\n      `summary-${new Date().toISOString().split('T')[0].replace(/-/g, '')}.json`\r\n    );\r\n\r\n    try {\r\n      await fs.writeFile(summaryPath, JSON.stringify(summary, null, 2));\r\n      logger.info('AutoLearningTask', `Summary written to ${summaryPath}`);\r\n    } catch (error) {\r\n      logger.error('AutoLearningTask', `Failed to write summary`, { error: error.message });\r\n    }\r\n\r\n    return summary;\r\n  }\r\n\r\n  /**\r\n   * Update success rate calculation\r\n   */\r\n  updateSuccessRate() {\r\n    if (this.stats.recordsProcessed > 0) {\r\n      this.stats.successRate = ((this.stats.recordsProcessed - this.stats.errorCount) / this.stats.recordsProcessed) * 100;\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Update running average confidence\r\n   */\r\n  updateAverageConfidence(newConfidence) {\r\n    if (this.stats.recordsProcessed === 1) {\r\n      this.stats.averageConfidence = newConfidence;\r\n    } else {\r\n      this.stats.averageConfidence = (\r\n        (this.stats.averageConfidence * (this.stats.recordsProcessed - 1)) + newConfidence\r\n      ) / this.stats.recordsProcessed;\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Format duration in human-readable format\r\n   */\r\n  formatDuration(milliseconds) {\r\n    const seconds = Math.floor(milliseconds / 1000);\r\n    const minutes = Math.floor(seconds / 60);\r\n    const hours = Math.floor(minutes / 60);\r\n\r\n    if (hours > 0) {\r\n      return `${hours}h ${minutes % 60}m`;\r\n    } else if (minutes > 0) {\r\n      return `${minutes}m ${seconds % 60}s`;\r\n    } else {\r\n      return `${seconds}s`;\r\n    }\r\n  }\r\n}\r\n\r\nmodule.exports = AutoLearningTaskService;\r\n"
    },
    "complexity": {
      "totalLines": 1050,
      "codeLines": 741,
      "commentLines": 152,
      "commentRatio": 0.1702127659574468,
      "averageLineLength": 34.68980963045912
    },
    "lastAnalyzed": "2025-07-28T07:20:01.096Z"
  },
  "contentHash": "0bf64f3e88da85ae2384dc05653e9418febfc08e3b61c892a140e9ed88e76329",
  "discoveredAt": "2025-07-28T07:20:01.096Z"
}