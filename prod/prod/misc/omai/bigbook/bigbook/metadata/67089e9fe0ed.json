{
  "id": "67089e9fe0ed",
  "originalPath": "/var/www/orthodox-church-mgmt/orthodoxmetrics/prod/server/routes/bigbook.js",
  "relativePath": "server/routes/bigbook.js",
  "name": "bigbook.js",
  "extension": ".js",
  "size": 115856,
  "modified": "2025-07-27T20:34:57.706Z",
  "created": "2025-07-24T22:50:28.108Z",
  "classification": {
    "type": "Server Scripts",
    "category": "Backend > Server",
    "confidence": 7
  },
  "metadata": {
    "fileStats": {
      "lines": 3687,
      "characters": 115852,
      "words": 10446
    },
    "classification": {
      "type": "Server Scripts",
      "category": "Backend > Server",
      "confidence": 7
    },
    "dependencies": [
      {
        "type": "npm_package",
        "name": "express",
        "line": 1
      },
      {
        "type": "npm_package",
        "name": "child_process",
        "line": 3
      },
      {
        "type": "npm_package",
        "name": "fs",
        "line": 4
      },
      {
        "type": "npm_package",
        "name": "path",
        "line": 5
      },
      {
        "type": "npm_package",
        "name": "mysql2/promise",
        "line": 6
      },
      {
        "type": "npm_package",
        "name": "uuid",
        "line": 7
      },
      {
        "type": "npm_package",
        "name": "multer",
        "line": 1591
      },
      {
        "type": "npm_package",
        "name": "adm-zip",
        "line": 1592
      },
      {
        "type": "npm_package",
        "name": "fs",
        "line": 2851
      },
      {
        "type": "npm_package",
        "name": "path",
        "line": 2852
      },
      {
        "type": "npm_package",
        "name": "fs",
        "line": 3081
      },
      {
        "type": "npm_package",
        "name": "path",
        "line": 3082
      },
      {
        "type": "npm_package",
        "name": "fs",
        "line": 3228
      },
      {
        "type": "npm_package",
        "name": "path",
        "line": 3229
      },
      {
        "type": "npm_package",
        "name": "child_process",
        "line": 3230
      },
      {
        "type": "npm_package",
        "name": "fs",
        "line": 3317
      },
      {
        "type": "npm_package",
        "name": "path",
        "line": 3318
      },
      {
        "type": "npm_package",
        "name": "fs",
        "line": 3363
      },
      {
        "type": "npm_package",
        "name": "path",
        "line": 3364
      },
      {
        "type": "npm_package",
        "name": "fs",
        "line": 3404
      },
      {
        "type": "npm_package",
        "name": "path",
        "line": 3405
      },
      {
        "type": "npm_package",
        "name": "fs",
        "line": 3427
      },
      {
        "type": "npm_package",
        "name": "path",
        "line": 3428
      },
      {
        "type": "npm_package",
        "name": "child_process",
        "line": 3429
      },
      {
        "type": "npm_package",
        "name": "fs",
        "line": 3533
      },
      {
        "type": "npm_package",
        "name": "path",
        "line": 3534
      },
      {
        "type": "npm_package",
        "name": "fs",
        "line": 3607
      },
      {
        "type": "npm_package",
        "name": "path",
        "line": 3608
      },
      {
        "type": "npm_package",
        "name": "fs",
        "line": 3644
      },
      {
        "type": "npm_package",
        "name": "path",
        "line": 3645
      }
    ],
    "security": {
      "findings": [
        {
          "type": "sensitive_data",
          "pattern": "process\\.env\\.([A-Z_]+)",
          "line": 686,
          "redacted": true
        },
        {
          "type": "sensitive_data",
          "pattern": "process\\.env\\.([A-Z_]+)",
          "line": 1144,
          "redacted": true
        },
        {
          "type": "sensitive_data",
          "pattern": "process\\.env\\.([A-Z_]+)",
          "line": 1145,
          "redacted": true
        },
        {
          "type": "sensitive_data",
          "pattern": "process\\.env\\.([A-Z_]+)",
          "line": 1146,
          "redacted": true
        },
        {
          "type": "sensitive_data",
          "pattern": "process\\.env\\.([A-Z_]+)",
          "line": 1147,
          "redacted": true
        },
        {
          "type": "sensitive_data",
          "pattern": "process\\.env\\.([A-Z_]+)",
          "line": 1235,
          "redacted": true
        },
        {
          "type": "sensitive_data",
          "pattern": "process\\.env\\.([A-Z_]+)",
          "line": 1236,
          "redacted": true
        },
        {
          "type": "sensitive_data",
          "pattern": "process\\.env\\.([A-Z_]+)",
          "line": 1237,
          "redacted": true
        },
        {
          "type": "sensitive_data",
          "pattern": "process\\.env\\.([A-Z_]+)",
          "line": 1238,
          "redacted": true
        },
        {
          "type": "sensitive_data",
          "pattern": "process\\.env\\.([A-Z_]+)",
          "line": 1652,
          "redacted": true
        },
        {
          "type": "sensitive_data",
          "pattern": "process\\.env\\.([A-Z_]+)",
          "line": 1702,
          "redacted": true
        },
        {
          "type": "sensitive_data",
          "pattern": "process\\.env\\.([A-Z_]+)",
          "line": 1725,
          "redacted": true
        },
        {
          "type": "sensitive_data",
          "pattern": "process\\.env\\.([A-Z_]+)",
          "line": 2069,
          "redacted": true
        },
        {
          "type": "sensitive_data",
          "pattern": "process\\.env\\.([A-Z_]+)",
          "line": 2076,
          "redacted": true
        }
      ],
      "hasSecurityIssues": true,
      "redactedContent": "const express = require('express');\r\nconst router = express.Router();\r\nconst { exec } = require('child_process');\r\nconst fs = require('fs').promises;\r\nconst path = require('path');\r\nconst mysql = require('mysql2/promise');\r\nconst { v4: uuidv4 } = require('uuid');\r\nconst EncryptedStorage = require('../utils/encryptedStorage');\r\nconst QuestionnaireParser = require('../utils/questionnaireParser');\r\nconst OMAIPathDiscovery = require('../services/omaiPathDiscovery');\r\n\r\n// Big Book configuration\r\nconst BIGBOOK_ROOT = '/var/www/orthodox-church-mgmt/orthodoxmetrics/prod/bigbook';\r\nconst TEMP_DIR = path.join(BIGBOOK_ROOT, 'storage/cache');\r\nconst LOG_DIR = path.join(BIGBOOK_ROOT, 'logs');\r\n\r\n// Initialize encrypted storage\r\nconst encryptedStorage = new EncryptedStorage();\r\nlet storageInitialized = false;\r\n\r\n// Initialize OMAI Path Discovery\r\nconst omaiDiscovery = new OMAIPathDiscovery();\r\n\r\n// Ensure directories exist\r\nasync function ensureDirectories() {\r\n  const dirs = [BIGBOOK_ROOT, TEMP_DIR, LOG_DIR];\r\n  for (const dir of dirs) {\r\n    try {\r\n      await fs.access(dir);\r\n    } catch {\r\n      await fs.mkdir(dir, { recursive: true });\r\n    }\r\n  }\r\n}\r\n\r\n// Initialize encrypted storage if not already done\r\nasync function ensureEncryptedStorage() {\r\n  if (!storageInitialized) {\r\n    try {\r\n      await encryptedStorage.initialize();\r\n      storageInitialized = true;\r\n    } catch (error) {\r\n      console.error('Failed to initialize encrypted storage:', error);\r\n      throw error;\r\n    }\r\n  }\r\n}\r\n\r\n// Log function\r\nasync function logToFile(filename, message) {\r\n  const timestamp = new Date().toISOString();\r\n  const logMessage = `[${timestamp}] ${message}\\n`;\r\n  await fs.appendFile(path.join(LOG_DIR, filename), logMessage);\r\n}\r\n\r\n// Database connection helper\r\nasync function getDbConnection(settings) {\r\n  return mysql.createConnection({\r\n    host: 'localhost',\r\n    user: settings.databaseUser || 'root',\r\n    password: settings.databasePassword || '',\r\n    database: settings.defaultDatabase || 'omai_db',\r\n    multipleStatements: true\r\n  });\r\n}\r\n\r\n// Execute SQL file\r\nasync function executeSqlFile(content, settings) {\r\n  const connection = await getDbConnection(settings);\r\n  \r\n  try {\r\n    const startTime = Date.now();\r\n    const [results] = await connection.execute(content);\r\n    const duration = Date.now() - startTime;\r\n    \r\n    await logToFile('execution.log', `SQL executed successfully in ${duration}ms`);\r\n    \r\n    return {\r\n      success: true,\r\n      output: `SQL executed successfully in ${duration}ms\\nAffected rows: ${results.affectedRows || 'N/A'}`,\r\n      duration,\r\n      results\r\n    };\r\n  } catch (error) {\r\n    await logToFile('execution.log', `SQL execution error: ${error.message}`);\r\n    throw error;\r\n  } finally {\r\n    await connection.end();\r\n  }\r\n}\r\n\r\n// Execute shell script\r\nasync function executeShellScript(content, settings) {\r\n  return new Promise((resolve, reject) => {\r\n    const tempFile = path.join(TEMP_DIR, `script_${uuidv4()}.sh`);\r\n    const startTime = Date.now();\r\n    \r\n    // Create temporary script file\r\n    fs.writeFile(tempFile, content, { mode: 0o755 })\r\n      .then(() => {\r\n        const command = settings.useSudo \r\n          ? `echo '${settings.sudoPassword}' | sudo -S ${tempFile}`\r\n          : tempFile;\r\n        \r\n        const child = exec(command, {\r\n          timeout: settings.timeout || 30000,\r\n          cwd: process.cwd(),\r\n          env: {\r\n            ...process.env,\r\n            DB_USER: settings.databaseUser,\r\n            DB_PASSWORD: settings.databasePassword,\r\n            DB_NAME: settings.defaultDatabase\r\n          }\r\n        }, async (error, stdout, stderr) => {\r\n          const duration = Date.now() - startTime;\r\n          \r\n          // Clean up temp file\r\n          try {\r\n            await fs.unlink(tempFile);\r\n          } catch (cleanupError) {\r\n            console.error('Failed to cleanup temp file:', cleanupError);\r\n          }\r\n          \r\n          if (error) {\r\n            await logToFile('execution.log', `Shell script execution error: ${error.message}`);\r\n            reject(error);\r\n          } else {\r\n            await logToFile('execution.log', `Shell script executed successfully in ${duration}ms`);\r\n            resolve({\r\n              success: true,\r\n              output: stdout,\r\n              error: stderr,\r\n              duration\r\n            });\r\n          }\r\n        });\r\n        \r\n        child.on('error', async (error) => {\r\n          await logToFile('execution.log', `Shell script process error: ${error.message}`);\r\n          reject(error);\r\n        });\r\n      })\r\n      .catch(reject);\r\n  });\r\n}\r\n\r\n// Execute JavaScript file\r\nasync function executeJavaScriptFile(content, settings) {\r\n  return new Promise((resolve, reject) => {\r\n    const tempFile = path.join(TEMP_DIR, `script_${uuidv4()}.js`);\r\n    const startTime = Date.now();\r\n    \r\n    // Create temporary script file\r\n    fs.writeFile(tempFile, content)\r\n      .then(() => {\r\n        const command = `node ${tempFile}`;\r\n        \r\n        const child = exec(command, {\r\n          timeout: settings.timeout || 30000,\r\n          cwd: process.cwd(),\r\n          env: {\r\n            ...process.env,\r\n            DB_USER: settings.databaseUser,\r\n            DB_PASSWORD: settings.databasePassword,\r\n            DB_NAME: settings.defaultDatabase\r\n          }\r\n        }, async (error, stdout, stderr) => {\r\n          const duration = Date.now() - startTime;\r\n          \r\n          // Clean up temp file\r\n          try {\r\n            await fs.unlink(tempFile);\r\n          } catch (cleanupError) {\r\n            console.error('Failed to cleanup temp file:', cleanupError);\r\n          }\r\n          \r\n          if (error) {\r\n            await logToFile('execution.log', `JavaScript execution error: ${error.message}`);\r\n            reject(error);\r\n          } else {\r\n            await logToFile('execution.log', `JavaScript executed successfully in ${duration}ms`);\r\n            resolve({\r\n              success: true,\r\n              output: stdout,\r\n              error: stderr,\r\n              duration\r\n            });\r\n          }\r\n        });\r\n        \r\n        child.on('error', async (error) => {\r\n          await logToFile('execution.log', `JavaScript process error: ${error.message}`);\r\n          reject(error);\r\n        });\r\n      })\r\n      .catch(reject);\r\n  });\r\n}\r\n\r\n// Execute Python file\r\nasync function executePythonFile(content, settings) {\r\n  return new Promise((resolve, reject) => {\r\n    const tempFile = path.join(TEMP_DIR, `script_${uuidv4()}.py`);\r\n    const startTime = Date.now();\r\n    \r\n    // Create temporary script file\r\n    fs.writeFile(tempFile, content)\r\n      .then(() => {\r\n        const command = `python3 ${tempFile}`;\r\n        \r\n        const child = exec(command, {\r\n          timeout: settings.timeout || 30000,\r\n          cwd: process.cwd(),\r\n          env: {\r\n            ...process.env,\r\n            DB_USER: settings.databaseUser,\r\n            DB_PASSWORD: settings.databasePassword,\r\n            DB_NAME: settings.defaultDatabase\r\n          }\r\n        }, async (error, stdout, stderr) => {\r\n          const duration = Date.now() - startTime;\r\n          \r\n          // Clean up temp file\r\n          try {\r\n            await fs.unlink(tempFile);\r\n          } catch (cleanupError) {\r\n            console.error('Failed to cleanup temp file:', cleanupError);\r\n          }\r\n          \r\n          if (error) {\r\n            await logToFile('execution.log', `Python execution error: ${error.message}`);\r\n            reject(error);\r\n          } else {\r\n            await logToFile('execution.log', `Python executed successfully in ${duration}ms`);\r\n            resolve({\r\n              success: true,\r\n              output: stdout,\r\n              error: stderr,\r\n              duration\r\n            });\r\n          }\r\n        });\r\n        \r\n        child.on('error', async (error) => {\r\n          await logToFile('execution.log', `Python process error: ${error.message}`);\r\n          reject(error);\r\n        });\r\n      })\r\n      .catch(reject);\r\n  });\r\n}\r\n\r\n// Process document files (markdown, text, etc.)\r\nasync function processDocumentFile(content, fileName, fileType) {\r\n  const timestamp = new Date().toISOString();\r\n  const docInfo = {\r\n    fileName,\r\n    fileType,\r\n    contentLength: content.length,\r\n    timestamp,\r\n    processed: true\r\n  };\r\n  \r\n  await logToFile('documents.log', `Document processed: ${fileName} (${fileType}) - ${content.length} characters`);\r\n  \r\n  return {\r\n    success: true,\r\n    output: `Document processed successfully\\nFile: ${fileName}\\nType: ${fileType}\\nSize: ${content.length} characters\\nTimestamp: ${timestamp}`,\r\n    documentInfo: docInfo\r\n  };\r\n}\r\n\r\n// Get file type from extension\r\nfunction getFileTypeFromExtension(extension) {\r\n  switch (extension.toLowerCase()) {\r\n    case 'sql':\r\n      return 'sql';\r\n    case 'md':\r\n    case 'markdown':\r\n      return 'markdown';\r\n    case 'js':\r\n    case 'jsx':\r\n    case 'ts':\r\n    case 'tsx':\r\n      return 'javascript';\r\n    case 'sh':\r\n    case 'bash':\r\n    case 'zsh':\r\n      return 'shell';\r\n    case 'py':\r\n    case 'python':\r\n      return 'python';\r\n    case 'html':\r\n    case 'htm':\r\n      return 'html';\r\n    case 'css':\r\n    case 'scss':\r\n    case 'sass':\r\n      return 'css';\r\n    case 'json':\r\n      return 'json';\r\n    case 'xml':\r\n      return 'xml';\r\n    case 'txt':\r\n    case 'log':\r\n      return 'text';\r\n    case 'jpg':\r\n    case 'jpeg':\r\n    case 'png':\r\n    case 'gif':\r\n    case 'svg':\r\n    case 'webp':\r\n      return 'image';\r\n    case 'mp4':\r\n    case 'avi':\r\n    case 'mov':\r\n    case 'wmv':\r\n      return 'video';\r\n    case 'mp3':\r\n    case 'wav':\r\n    case 'ogg':\r\n      return 'audio';\r\n    case 'zip':\r\n    case 'tar':\r\n    case 'gz':\r\n    case 'rar':\r\n      return 'archive';\r\n    case 'pdf':\r\n      return 'pdf';\r\n    default:\r\n      return 'other';\r\n  }\r\n}\r\n\r\n// POST /api/bigbook/execute - Execute a file\r\nrouter.post('/execute', async (req, res) => {\r\n  try {\r\n    await ensureDirectories();\r\n    \r\n    const { fileId, fileName, content, type, settings } = req.body;\r\n    \r\n    if (!content || !fileName) {\r\n      return res.status(400).json({\r\n        success: false,\r\n        error: 'File content and name are required'\r\n      });\r\n    }\r\n    \r\n    await logToFile('execution.log', `Starting execution: ${fileName} (${type})`);\r\n    \r\n    let result;\r\n    \r\n    if (type === 'sql') {\r\n      result = await executeSqlFile(content, settings);\r\n    } else if (type === 'shell') {\r\n      result = await executeShellScript(content, settings);\r\n    } else if (type === 'javascript') {\r\n      result = await executeJavaScriptFile(content, settings);\r\n    } else if (type === 'python') {\r\n      result = await executePythonFile(content, settings);\r\n    } else {\r\n      result = await processDocumentFile(content, fileName, getFileTypeFromExtension(path.extname(fileName)));\r\n    }\r\n    \r\n    // Store execution record in Big Book database\r\n    try {\r\n      const connection = await getDbConnection(settings);\r\n      await connection.execute(`\r\n        INSERT INTO bigbook_executions (doc_id, execution_type, status, duration_ms, output, error_message, executed_by, environment)\r\n        VALUES (?, ?, ?, ?, ?, ?, ?, ?)\r\n      `, [\r\n        fileId,\r\n        'manual',\r\n        result.success ? 'success' : 'failed',\r\n        result.duration,\r\n        result.output || null,\r\n        result.error || null,\r\n        'admin',\r\n        'production'\r\n      ]);\r\n      await connection.end();\r\n    } catch (dbError) {\r\n      console.error('Failed to log execution to database:', dbError);\r\n    }\r\n    \r\n    res.json(result);\r\n    \r\n  } catch (error) {\r\n    console.error('Big Book execution error:', error);\r\n    await logToFile('execution.log', `Execution error: ${error.message}`);\r\n    \r\n    res.status(500).json({\r\n      success: false,\r\n      error: error.message || 'Execution failed'\r\n    });\r\n  }\r\n});\r\n\r\n// POST /api/bigbook/settings - Save Big Book settings\r\nrouter.post('/settings', async (req, res) => {\r\n  try {\r\n    await ensureDirectories();\r\n    \r\n    const settings = req.body;\r\n    const settingsFile = path.join(BIGBOOK_ROOT, 'config/settings.json');\r\n    \r\n    // Save settings to file\r\n    await fs.writeFile(settingsFile, JSON.stringify(settings, null, 2));\r\n    \r\n    // Also save to database\r\n    try {\r\n      const connection = await getDbConnection(settings);\r\n      \r\n      // Clear existing settings\r\n      await connection.execute('DELETE FROM bigbook_config WHERE config_key LIKE \"user_%\"');\r\n      \r\n      // Insert new settings\r\n      const settingsToSave = [\r\n        ['user_database_user', settings.databaseUser, 'string'],\r\n        ['user_use_sudo', settings.useSudo.toString(), 'boolean'],\r\n        ['user_default_database', settings.defaultDatabase, 'string'],\r\n        ['user_script_timeout', settings.scriptTimeout.toString(), 'number'],\r\n        ['user_max_file_size', settings.maxFileSize.toString(), 'number']\r\n      ];\r\n      \r\n      for (const [key, value, type] of settingsToSave) {\r\n        await connection.execute(`\r\n          INSERT INTO bigbook_config (config_key, config_value, config_type, description, is_system)\r\n          VALUES (?, ?, ?, ?, FALSE)\r\n          ON DUPLICATE KEY UPDATE config_value = VALUES(config_value)\r\n        `, [key, value, type, `User setting: ${key}`]);\r\n      }\r\n      \r\n      await connection.end();\r\n    } catch (dbError) {\r\n      console.error('Failed to save settings to database:', dbError);\r\n    }\r\n    \r\n    await logToFile('execution.log', 'Big Book settings saved');\r\n    \r\n    res.json({\r\n      success: true,\r\n      message: 'Settings saved successfully'\r\n    });\r\n    \r\n  } catch (error) {\r\n    console.error('Big Book settings error:', error);\r\n    await logToFile('execution.log', `Settings error: ${error.message}`);\r\n    \r\n    res.status(500).json({\r\n      success: false,\r\n      error: error.message || 'Failed to save settings'\r\n    });\r\n  }\r\n});\r\n\r\n// GET /api/bigbook/settings - Get Big Book settings\r\nrouter.get('/settings', async (req, res) => {\r\n  try {\r\n    await ensureDirectories();\r\n    \r\n    const settingsFile = path.join(BIGBOOK_ROOT, 'config/settings.json');\r\n    \r\n    try {\r\n      const settingsData = await fs.readFile(settingsFile, 'utf8');\r\n      const settings = JSON.parse(settingsData);\r\n      res.json({\r\n        success: true,\r\n        settings\r\n      });\r\n    } catch (fileError) {\r\n      // Return default settings if file doesn't exist\r\n      const defaultSettings = {\r\n        databaseUser: 'root',\r\n        databasePassword: '',\r\n        useSudo: true,\r\n        sudoPassword: '',\r\n        defaultDatabase: 'orthodoxmetrics_db',\r\n        scriptTimeout: 30000,\r\n        maxFileSize: 10485760\r\n      };\r\n      \r\n      res.json({\r\n        success: true,\r\n        settings: defaultSettings\r\n      });\r\n    }\r\n    \r\n  } catch (error) {\r\n    console.error('Big Book get settings error:', error);\r\n    res.status(500).json({\r\n      success: false,\r\n      error: error.message || 'Failed to get settings'\r\n    });\r\n  }\r\n});\r\n\r\n// POST /api/bigbook/process-all - Process all uploaded .md files\r\nrouter.post('/process-all', async (req, res) => {\r\n  try {\r\n    await ensureDirectories();\r\n    \r\n    const { useSecureStorage = true, retryOnFailure = true } = req.body;\r\n    const results = {\r\n      success: true,\r\n      processedFiles: [],\r\n      failedFiles: [],\r\n      secureStorage: {\r\n        mounted: false,\r\n        mountPath: '/mnt/bigbook_secure',\r\n        retryCount: 0\r\n      },\r\n      summary: {\r\n        totalFiles: 0,\r\n        processedCount: 0,\r\n        failedCount: 0,\r\n        startTime: new Date().toISOString()\r\n      }\r\n    };\r\n\r\n    await logToFile('process-all.log', 'Starting batch file processing...');\r\n\r\n    // Step 1: Handle encrypted storage mounting if requested\r\n    if (useSecureStorage) {\r\n      results.secureStorage.mounted = await mountSecureStorage(results.secureStorage, retryOnFailure);\r\n      \r\n      if (!results.secureStorage.mounted) {\r\n        await logToFile('process-all.log', 'Warning: Continuing without secure storage');\r\n      }\r\n    }\r\n\r\n    // Step 2: Get all .md files from upload cache\r\n    const uploadCacheDir = path.join(TEMP_DIR, 'uploads');\r\n    let mdFiles = [];\r\n    \r\n    try {\r\n      await fs.access(uploadCacheDir);\r\n      const files = await fs.readdir(uploadCacheDir);\r\n      mdFiles = files.filter(file => file.endsWith('.md'));\r\n    } catch (error) {\r\n      await logToFile('process-all.log', `Upload cache directory not found: ${error.message}`);\r\n    }\r\n\r\n    results.summary.totalFiles = mdFiles.length;\r\n    await logToFile('process-all.log', `Found ${mdFiles.length} .md files to process`);\r\n\r\n    // Step 3: Process each .md file\r\n    for (const fileName of mdFiles) {\r\n      const filePath = path.join(uploadCacheDir, fileName);\r\n      const fileResult = {\r\n        fileName,\r\n        success: false,\r\n        error: null,\r\n        size: 0,\r\n        processedAt: new Date().toISOString(),\r\n        securelyStored: false\r\n      };\r\n\r\n      try {\r\n        // Get file stats\r\n        const stats = await fs.stat(filePath);\r\n        fileResult.size = stats.size;\r\n\r\n        // Read and process the file\r\n        const content = await fs.readFile(filePath, 'utf8');\r\n        const processResult = await processMarkdownFile(content, fileName);\r\n        \r\n        if (processResult.success) {\r\n          fileResult.success = true;\r\n          \r\n          // Move to secure storage if available\r\n          if (results.secureStorage.mounted) {\r\n            try {\r\n              const secureFilePath = path.join(results.secureStorage.mountPath, fileName);\r\n              await fs.copyFile(filePath, secureFilePath);\r\n              await fs.unlink(filePath); // Remove from cache after successful copy\r\n              fileResult.securelyStored = true;\r\n              await logToFile('process-all.log', `${fileName}: Moved to secure storage`);\r\n            } catch (storageError) {\r\n              await logToFile('process-all.log', `${fileName}: Failed to move to secure storage: ${storageError.message}`);\r\n            }\r\n          }\r\n          \r\n          results.processedFiles.push(fileResult);\r\n          results.summary.processedCount++;\r\n          await logToFile('process-all.log', `${fileName}: Processed successfully (${fileResult.size} bytes)`);\r\n        } else {\r\n          fileResult.error = processResult.error || 'Processing failed';\r\n          results.failedFiles.push(fileResult);\r\n          results.summary.failedCount++;\r\n          await logToFile('process-all.log', `${fileName}: Processing failed - ${fileResult.error}`);\r\n        }\r\n      } catch (error) {\r\n        fileResult.error = error.message;\r\n        results.failedFiles.push(fileResult);\r\n        results.summary.failedCount++;\r\n        await logToFile('process-all.log', `${fileName}: Error - ${error.message}`);\r\n      }\r\n    }\r\n\r\n    results.summary.endTime = new Date().toISOString();\r\n    const duration = new Date(results.summary.endTime) - new Date(results.summary.startTime);\r\n    results.summary.durationMs = duration;\r\n\r\n    await logToFile('process-all.log', \r\n      `Batch processing completed: ${results.summary.processedCount}/${results.summary.totalFiles} files processed in ${duration}ms`);\r\n\r\n    res.json(results);\r\n\r\n  } catch (error) {\r\n    console.error('Batch processing error:', error);\r\n    await logToFile('process-all.log', `Batch processing error: ${error.message}`);\r\n    \r\n    res.status(500).json({\r\n      success: false,\r\n      error: error.message || 'Batch processing failed'\r\n    });\r\n  }\r\n});\r\n\r\n// POST /api/bigbook/test-secure-mount - Test encrypted storage mount\r\nrouter.post('/test-secure-mount', async (req, res) => {\r\n  try {\r\n    const mountPath = '/mnt/bigbook_secure';\r\n    const testResult = {\r\n      mountPath,\r\n      accessible: false,\r\n      writable: false,\r\n      error: null,\r\n      testTime: new Date().toISOString()\r\n    };\r\n\r\n    try {\r\n      // Test if mount path exists and is accessible\r\n      await fs.access(mountPath);\r\n      testResult.accessible = true;\r\n\r\n      // Test if writable\r\n      const testFile = path.join(mountPath, `.test-write-${Date.now()}.tmp`);\r\n      await fs.writeFile(testFile, 'test');\r\n      await fs.unlink(testFile);\r\n      testResult.writable = true;\r\n\r\n      await logToFile('mount-test.log', `Secure storage test passed: ${mountPath}`);\r\n    } catch (error) {\r\n      testResult.error = error.message;\r\n      await logToFile('mount-test.log', `Secure storage test failed: ${error.message}`);\r\n    }\r\n\r\n    res.json({\r\n      success: true,\r\n      testResult\r\n    });\r\n\r\n  } catch (error) {\r\n    console.error('Mount test error:', error);\r\n    res.status(500).json({\r\n      success: false,\r\n      error: error.message || 'Mount test failed'\r\n    });\r\n  }\r\n});\r\n\r\n// Helper function to mount secure storage with retry logic\r\nasync function mountSecureStorage(storageInfo, retryOnFailure = true) {\r\n  const maxRetries = retryOnFailure ? 3 : 1;\r\n  const retryDelay = 2000; // 2 seconds\r\n  \r\n  for (let attempt = 1; attempt <= maxRetries; attempt++) {\r\n    storageInfo.retryCount = attempt;\r\n    \r\n    try {\r\n      // Check if already mounted\r\n      const testPath = path.join(storageInfo.mountPath, '.mount-test');\r\n      try {\r\n        await fs.access(storageInfo.mountPath);\r\n        await fs.writeFile(testPath, 'test');\r\n        await fs.unlink(testPath);\r\n        await logToFile('mount.log', `Secure storage already mounted: ${storageInfo.mountPath}`);\r\n        return true;\r\n      } catch (e) {\r\n        // Not mounted or not writable, proceed with mount attempt\r\n      }\r\n\r\n      // Attempt to mount\r\n      const mountCommand = `mount -t ecryptfs ${BIGBOOK_ROOT}/encrypted ${storageInfo.mountPath} -o key=passphrase,ecryptfs_cipher=aes,ecryptfs_key_bytes=32,ecryptfs_passthrough=no,ecryptfs_enable_filename_crypto=yes,passwd=${process.env.[REDACTED] || 'default_key'}`;\r\n      \r\n      await logToFile('mount.log', `Mount attempt ${attempt}/${maxRetries}: ${storageInfo.mountPath}`);\r\n      \r\n      await new Promise((resolve, reject) => {\r\n        exec(mountCommand, (error, stdout, stderr) => {\r\n          if (error) {\r\n            reject(new Error(`Mount failed: ${error.message}\\nStderr: ${stderr}`));\r\n          } else {\r\n            resolve(stdout);\r\n          }\r\n        });\r\n      });\r\n\r\n      // Verify mount was successful\r\n      await fs.writeFile(testPath, 'test');\r\n      await fs.unlink(testPath);\r\n      \r\n      await logToFile('mount.log', `Secure storage mounted successfully on attempt ${attempt}`);\r\n      return true;\r\n\r\n    } catch (error) {\r\n      await logToFile('mount.log', `Mount attempt ${attempt} failed: ${error.message}`);\r\n      \r\n      if (attempt < maxRetries) {\r\n        await logToFile('mount.log', `Retrying in ${retryDelay/1000} seconds...`);\r\n        await new Promise(resolve => setTimeout(resolve, retryDelay));\r\n      } else {\r\n        await logToFile('mount.log', `All mount attempts failed. Continuing without secure storage.`);\r\n      }\r\n    }\r\n  }\r\n  \r\n  return false;\r\n}\r\n\r\n// Helper function to process markdown files\r\nasync function processMarkdownFile(content, fileName) {\r\n  try {\r\n    // Initialize encrypted storage if needed\r\n    await ensureEncryptedStorage();\r\n\r\n    // Process the markdown content\r\n    const fileType = getFileTypeFromContent(content);\r\n    let processResult;\r\n\r\n    if (fileType === 'questionnaire') {\r\n      // Use questionnaire parser\r\n      const parser = new QuestionnaireParser();\r\n      processResult = await parser.parseMarkdown(content);\r\n    } else {\r\n      // Generic document processing\r\n      processResult = await processDocumentFile(content, fileName, 'markdown');\r\n    }\r\n\r\n    // Store in database\r\n    const connection = await mysql.createConnection({\r\n      host: 'localhost',\r\n      user: 'root',\r\n      password: '',\r\n      database: 'omai_db'\r\n    });\r\n\r\n    try {\r\n      const docId = uuidv4();\r\n      await connection.execute(`\r\n        INSERT INTO bigbook_documents (id, filename, content_type, file_size, status, created_at, processed_at)\r\n        VALUES (?, ?, ?, ?, 'processed', NOW(), NOW())\r\n      `, [docId, fileName, fileType, content.length]);\r\n\r\n      await connection.end();\r\n    } catch (dbError) {\r\n      console.error('Database storage failed:', dbError);\r\n      // Continue processing even if DB storage fails\r\n    }\r\n\r\n    return {\r\n      success: true,\r\n      type: fileType,\r\n      result: processResult\r\n    };\r\n\r\n  } catch (error) {\r\n    return {\r\n      success: false,\r\n      error: error.message\r\n    };\r\n  }\r\n}\r\n\r\n// Helper function to detect file type from content\r\nfunction getFileTypeFromContent(content) {\r\n  if (content.includes('# Questionnaire') || content.includes('## Questions')) {\r\n    return 'questionnaire';\r\n  } else if (content.includes('```sql')) {\r\n    return 'sql-document';\r\n  } else if (content.includes('```javascript') || content.includes('```js')) {\r\n    return 'javascript-document';\r\n  } else if (content.includes('```python')) {\r\n    return 'python-document';\r\n  } else {\r\n    return 'markdown';\r\n  }\r\n}\r\n\r\n// GET /api/bigbook/status - Get Big Book system status\r\nrouter.get('/status', async (req, res) => {\r\n  try {\r\n    await ensureDirectories();\r\n    \r\n    const status = {\r\n      system: {\r\n        bigbookRoot: BIGBOOK_ROOT,\r\n        tempDir: TEMP_DIR,\r\n        logDir: LOG_DIR,\r\n        directoriesExist: true\r\n      },\r\n      database: {\r\n        connected: false,\r\n        tablesExist: false\r\n      },\r\n      files: {\r\n        totalDocuments: 0,\r\n        recentExecutions: 0\r\n      }\r\n    };\r\n    \r\n    // Check database connection\r\n    try {\r\n      const connection = await mysql.createConnection({\r\n        host: 'localhost',\r\n        user: 'root',\r\n        password: '',\r\n        database: 'omai_db'\r\n      });\r\n      \r\n      const [tables] = await connection.execute(`\r\n        SELECT COUNT(*) as count \r\n        FROM information_schema.tables \r\n        WHERE table_schema = 'omai_db' \r\n        AND table_name LIKE 'bigbook_%'\r\n      `);\r\n      \r\n      status.database.connected = true;\r\n      status.database.tablesExist = tables[0].count > 0;\r\n      \r\n      // Get document count\r\n      const [docCount] = await connection.execute('SELECT COUNT(*) as count FROM bigbook_documents');\r\n      status.files.totalDocuments = docCount[0].count;\r\n      \r\n      // Get recent executions\r\n      const [execCount] = await connection.execute(`\r\n        SELECT COUNT(*) as count \r\n        FROM bigbook_executions \r\n        WHERE executed_at >= DATE_SUB(NOW(), INTERVAL 24 HOUR)\r\n      `);\r\n      status.files.recentExecutions = execCount[0].count;\r\n      \r\n      await connection.end();\r\n    } catch (dbError) {\r\n      console.error('Database status check failed:', dbError);\r\n    }\r\n    \r\n    res.json({\r\n      success: true,\r\n      status\r\n    });\r\n    \r\n  } catch (error) {\r\n    console.error('Big Book status error:', error);\r\n    res.status(500).json({\r\n      success: false,\r\n      error: error.message || 'Failed to get status'\r\n    });\r\n  }\r\n});\r\n\r\n// GET /api/bigbook/logs - Get recent logs\r\nrouter.get('/logs', async (req, res) => {\r\n  try {\r\n    await ensureDirectories();\r\n    \r\n    const { type = 'execution', lines = 50 } = req.query;\r\n    const logFile = path.join(LOG_DIR, `${type}.log`);\r\n    \r\n    try {\r\n      const logContent = await fs.readFile(logFile, 'utf8');\r\n      const logLines = logContent.split('\\n').filter(line => line.trim()).slice(-lines);\r\n      \r\n      res.json({\r\n        success: true,\r\n        logs: logLines,\r\n        type,\r\n        totalLines: logLines.length\r\n      });\r\n    } catch (fileError) {\r\n      res.json({\r\n        success: true,\r\n        logs: [],\r\n        type,\r\n        totalLines: 0\r\n      });\r\n    }\r\n    \r\n  } catch (error) {\r\n    console.error('Big Book logs error:', error);\r\n    res.status(500).json({\r\n      success: false,\r\n      error: error.message || 'Failed to get logs'\r\n    });\r\n  }\r\n});\r\n\r\n// POST /api/bigbook/upload - Upload file to Big Book encrypted storage\r\nrouter.post('/upload', async (req, res) => {\r\n  try {\r\n    await ensureDirectories();\r\n    await ensureEncryptedStorage();\r\n    \r\n    const { fileName, content, fileType } = req.body;\r\n    \r\n    if (!fileName || !content) {\r\n      return res.status(400).json({\r\n        success: false,\r\n        error: 'File name and content are required'\r\n      });\r\n    }\r\n    \r\n    const fileId = uuidv4();\r\n    \r\n    // Check if this is a questionnaire file\r\n    let questionnaireMetadata = null;\r\n    if (path.extname(fileName).toLowerCase() === '.tsx') {\r\n      questionnaireMetadata = QuestionnaireParser.parseQuestionnaire(fileName, content);\r\n      \r\n      if (questionnaireMetadata) {\r\n        // Validate content for security\r\n        const validation = QuestionnaireParser.validateContent(content);\r\n        if (!validation.isValid) {\r\n          return res.status(400).json({\r\n            success: false,\r\n            error: 'Questionnaire validation failed',\r\n            issues: validation.issues,\r\n            warnings: validation.warnings\r\n          });\r\n        }\r\n        \r\n        // Log questionnaire detection\r\n        await logToFile('execution.log', `Questionnaire detected: ${fileName} -> ${questionnaireMetadata.title} (${questionnaireMetadata.ageGroup})`);\r\n      }\r\n    }\r\n    \r\n    // Store file in encrypted storage\r\n    const storageResult = await encryptedStorage.storeFile(fileId, fileName, content, fileType);\r\n    \r\n    // Log upload\r\n    await logToFile('execution.log', `File uploaded to encrypted storage: ${fileName} -> ${storageResult.encryptedPath}`);\r\n    \r\n    res.json({\r\n      success: true,\r\n      fileId,\r\n      encryptedPath: storageResult.encryptedPath,\r\n      originalName: storageResult.originalName,\r\n      fileType: storageResult.fileType,\r\n      isQuestionnaire: !!questionnaireMetadata,\r\n      questionnaireMetadata: questionnaireMetadata,\r\n      message: 'File uploaded to encrypted storage successfully'\r\n    });\r\n    \r\n  } catch (error) {\r\n    console.error('Big Book upload error:', error);\r\n    await logToFile('execution.log', `Upload error: ${error.message}`);\r\n    \r\n    res.status(500).json({\r\n      success: false,\r\n      error: error.message || 'Upload failed'\r\n    });\r\n  }\r\n});\r\n\r\n// GET /api/bigbook/storage/status - Get encrypted storage status\r\nrouter.get('/storage/status', async (req, res) => {\r\n  try {\r\n    await ensureEncryptedStorage();\r\n    const status = await encryptedStorage.getStatus();\r\n    \r\n    res.json({\r\n      success: true,\r\n      status\r\n    });\r\n  } catch (error) {\r\n    console.error('Storage status error:', error);\r\n    res.status(500).json({\r\n      success: false,\r\n      error: error.message || 'Failed to get storage status'\r\n    });\r\n  }\r\n});\r\n\r\n// GET /api/bigbook/storage/files - List files in encrypted storage\r\nrouter.get('/storage/files', async (req, res) => {\r\n  try {\r\n    await ensureEncryptedStorage();\r\n    const files = await encryptedStorage.listFiles();\r\n    \r\n    res.json({\r\n      success: true,\r\n      files\r\n    });\r\n  } catch (error) {\r\n    console.error('Storage files list error:', error);\r\n    res.status(500).json({\r\n      success: false,\r\n      error: error.message || 'Failed to list files'\r\n    });\r\n  }\r\n});\r\n\r\n// GET /api/bigbook/storage/file/:fileId - Retrieve file from encrypted storage\r\nrouter.get('/storage/file/:fileId', async (req, res) => {\r\n  try {\r\n    await ensureEncryptedStorage();\r\n    \r\n    const { fileId } = req.params;\r\n    const { encryptedPath } = req.query;\r\n    \r\n    if (!encryptedPath) {\r\n      return res.status(400).json({\r\n        success: false,\r\n        error: 'Encrypted path is required'\r\n      });\r\n    }\r\n    \r\n    const content = await encryptedStorage.retrieveFile(fileId, encryptedPath);\r\n    \r\n    res.json({\r\n      success: true,\r\n      fileId,\r\n      content,\r\n      retrievedAt: new Date().toISOString()\r\n    });\r\n  } catch (error) {\r\n    console.error('File retrieval error:', error);\r\n    res.status(500).json({\r\n      success: false,\r\n      error: error.message || 'Failed to retrieve file'\r\n    });\r\n  }\r\n});\r\n\r\n// DELETE /api/bigbook/storage/file/:fileId - Delete file from encrypted storage\r\nrouter.delete('/storage/file/:fileId', async (req, res) => {\r\n  try {\r\n    await ensureEncryptedStorage();\r\n    \r\n    const { fileId } = req.params;\r\n    const { encryptedPath } = req.query;\r\n    \r\n    if (!encryptedPath) {\r\n      return res.status(400).json({\r\n        success: false,\r\n        error: 'Encrypted path is required'\r\n      });\r\n    }\r\n    \r\n    await encryptedStorage.deleteFile(encryptedPath);\r\n    \r\n    res.json({\r\n      success: true,\r\n      fileId,\r\n      message: 'File deleted from encrypted storage successfully'\r\n    });\r\n  } catch (error) {\r\n    console.error('File deletion error:', error);\r\n    res.status(500).json({\r\n      success: false,\r\n      error: error.message || 'Failed to delete file'\r\n    });\r\n  }\r\n});\r\n\r\n// POST /api/bigbook/storage/mount - Mount encrypted volume\r\nrouter.post('/storage/mount', async (req, res) => {\r\n  try {\r\n    await ensureEncryptedStorage();\r\n    \r\n    res.json({\r\n      success: true,\r\n      message: 'Encrypted volume mounted successfully'\r\n    });\r\n  } catch (error) {\r\n    console.error('Mount error:', error);\r\n    res.status(500).json({\r\n      success: false,\r\n      error: error.message || 'Failed to mount encrypted volume'\r\n    });\r\n  }\r\n});\r\n\r\n// POST /api/bigbook/storage/unmount - Unmount encrypted volume\r\nrouter.post('/storage/unmount', async (req, res) => {\r\n  try {\r\n    await encryptedStorage.unmountEncryptedVolume();\r\n    \r\n    res.json({\r\n      success: true,\r\n      message: 'Encrypted volume unmounted successfully'\r\n    });\r\n  } catch (error) {\r\n    console.error('Unmount error:', error);\r\n    res.status(500).json({\r\n      success: false,\r\n      error: error.message || 'Failed to unmount encrypted volume'\r\n    });\r\n  }\r\n});\r\n\r\n// POST /api/bigbook/storage/rotate-key - Rotate encryption key\r\nrouter.post('/storage/rotate-key', async (req, res) => {\r\n  try {\r\n    await ensureEncryptedStorage();\r\n    await encryptedStorage.rotateKey();\r\n    \r\n    res.json({\r\n      success: true,\r\n      message: 'Encryption key rotated successfully'\r\n    });\r\n  } catch (error) {\r\n    console.error('Key rotation error:', error);\r\n    res.status(500).json({\r\n      success: false,\r\n      error: error.message || 'Failed to rotate encryption key'\r\n    });\r\n  }\r\n});\r\n\r\n// POST /api/bigbook/submit-response - Submit questionnaire response\r\nrouter.post('/submit-response', async (req, res) => {\r\n  try {\r\n    const { \r\n      questionnaireId, \r\n      userId, \r\n      responses, \r\n      ageGroup, \r\n      questionnaireTitle, \r\n      progressPercent, \r\n      isCompleted \r\n    } = req.body;\r\n    \r\n    if (!questionnaireId || !responses) {\r\n      return res.status(400).json({\r\n        success: false,\r\n        error: 'Questionnaire ID and responses are required'\r\n      });\r\n    }\r\n    \r\n    // Connect to database\r\n    const connection = await mysql.createConnection({\r\n      host: process.env.[REDACTED] || 'localhost',\r\n      user: process.env.[REDACTED] || 'root',\r\n      password: process.env.[REDACTED] || '',\r\n      database: process.env.[REDACTED] || 'orthodoxmetrics_db'\r\n    });\r\n    \r\n    try {\r\n      // Check if response already exists\r\n      const [existingResponse] = await connection.execute(\r\n        'SELECT id, responses, progress_percent FROM omai_survey_responses WHERE questionnaire_id = ? AND user_id = ?',\r\n        [questionnaireId, userId || null]\r\n      );\r\n      \r\n      if (existingResponse.length > 0) {\r\n        // Update existing response\r\n        const updateQuery = `\r\n          UPDATE omai_survey_responses \r\n          SET responses = ?, \r\n              progress_percent = ?, \r\n              is_completed = ?, \r\n              completed_at = ?,\r\n              updated_at = CURRENT_TIMESTAMP\r\n          WHERE id = ?\r\n        `;\r\n        \r\n        await connection.execute(updateQuery, [\r\n          JSON.stringify(responses),\r\n          progressPercent || 0,\r\n          isCompleted || false,\r\n          isCompleted ? new Date() : null,\r\n          existingResponse[0].id\r\n        ]);\r\n        \r\n        await logToFile('questionnaire.log', `Updated questionnaire response: ${questionnaireId} for user ${userId || 'anonymous'}`);\r\n        \r\n        res.json({\r\n          success: true,\r\n          responseId: existingResponse[0].id,\r\n          action: 'updated',\r\n          message: 'Response updated successfully'\r\n        });\r\n      } else {\r\n        // Insert new response\r\n        const insertQuery = `\r\n          INSERT INTO omai_survey_responses \r\n          (questionnaire_id, user_id, responses, age_group, questionnaire_title, progress_percent, is_completed, completed_at)\r\n          VALUES (?, ?, ?, ?, ?, ?, ?, ?)\r\n        `;\r\n        \r\n        const [result] = await connection.execute(insertQuery, [\r\n          questionnaireId,\r\n          userId || null,\r\n          JSON.stringify(responses),\r\n          ageGroup || null,\r\n          questionnaireTitle || null,\r\n          progressPercent || 0,\r\n          isCompleted || false,\r\n          isCompleted ? new Date() : null\r\n        ]);\r\n        \r\n        await logToFile('questionnaire.log', `New questionnaire response: ${questionnaireId} for user ${userId || 'anonymous'} (ID: ${result.insertId})`);\r\n        \r\n        res.json({\r\n          success: true,\r\n          responseId: result.insertId,\r\n          action: 'created',\r\n          message: 'Response saved successfully'\r\n        });\r\n      }\r\n    } finally {\r\n      await connection.end();\r\n    }\r\n    \r\n  } catch (error) {\r\n    console.error('Questionnaire response submission error:', error);\r\n    await logToFile('questionnaire.log', `Response submission error: ${error.message}`);\r\n    \r\n    res.status(500).json({\r\n      success: false,\r\n      error: error.message || 'Failed to save response'\r\n    });\r\n  }\r\n});\r\n\r\n// GET /api/bigbook/responses/:questionnaireId - Get responses for a questionnaire\r\nrouter.get('/responses/:questionnaireId', async (req, res) => {\r\n  try {\r\n    const { questionnaireId } = req.params;\r\n    const { userId } = req.query;\r\n    \r\n    const connection = await mysql.createConnection({\r\n      host: process.env.[REDACTED] || 'localhost',\r\n      user: process.env.[REDACTED] || 'root',\r\n      password: process.env.[REDACTED] || '',\r\n      database: process.env.[REDACTED] || 'orthodoxmetrics_db'\r\n    });\r\n    \r\n    try {\r\n      let query = 'SELECT * FROM omai_survey_responses WHERE questionnaire_id = ?';\r\n      let params = [questionnaireId];\r\n      \r\n      if (userId) {\r\n        query += ' AND user_id = ?';\r\n        params.push(userId);\r\n      }\r\n      \r\n      query += ' ORDER BY created_at DESC';\r\n      \r\n      const [responses] = await connection.execute(query, params);\r\n      \r\n      res.json({\r\n        success: true,\r\n        responses: responses.map(response => ({\r\n          ...response,\r\n          responses: JSON.parse(response.responses)\r\n        }))\r\n      });\r\n    } finally {\r\n      await connection.end();\r\n    }\r\n    \r\n  } catch (error) {\r\n    console.error('Get questionnaire responses error:', error);\r\n    \r\n    res.status(500).json({\r\n      success: false,\r\n      error: error.message || 'Failed to retrieve responses'\r\n    });\r\n  }\r\n});\r\n\r\n// =====================================================\r\n// OMAI PATH DISCOVERY ENDPOINTS\r\n// =====================================================\r\n\r\n/**\r\n * Initialize OMAI path discovery system\r\n * POST /api/bigbook/omai/initialize\r\n */\r\nrouter.post('/omai/initialize', async (req, res) => {\r\n  try {\r\n    await logToFile('execution.log', 'OMAI Path Discovery initialization requested');\r\n    \r\n    const result = await omaiDiscovery.initialize();\r\n    \r\n    res.json({\r\n      success: true,\r\n      message: 'OMAI Path Discovery system initialized successfully',\r\n      initialized: result,\r\n      timestamp: new Date().toISOString()\r\n    });\r\n    \r\n    await logToFile('execution.log', 'OMAI Path Discovery initialization completed');\r\n  } catch (error) {\r\n    await logToFile('execution.log', `OMAI Path Discovery initialization failed: ${error.message}`);\r\n    res.status(500).json({\r\n      success: false,\r\n      error: 'Failed to initialize OMAI Path Discovery system',\r\n      details: error.message\r\n    });\r\n  }\r\n});\r\n\r\n/**\r\n * Start OMAI file discovery process\r\n * POST /api/bigbook/omai/discover\r\n */\r\nrouter.post('/omai/discover', async (req, res) => {\r\n  try {\r\n    await logToFile('execution.log', 'OMAI file discovery process started');\r\n    \r\n    // Start discovery in background\r\n    omaiDiscovery.discoverFiles().then(result => {\r\n      logToFile('execution.log', `OMAI file discovery completed: ${result.processedFiles} files processed`);\r\n    }).catch(error => {\r\n      logToFile('execution.log', `OMAI file discovery failed: ${error.message}`);\r\n    });\r\n    \r\n    res.json({\r\n      success: true,\r\n      message: 'OMAI file discovery process started',\r\n      status: 'running',\r\n      timestamp: new Date().toISOString()\r\n    });\r\n  } catch (error) {\r\n    await logToFile('execution.log', `OMAI file discovery start failed: ${error.message}`);\r\n    res.status(500).json({\r\n      success: false,\r\n      error: 'Failed to start OMAI file discovery',\r\n      details: error.message\r\n    });\r\n  }\r\n});\r\n\r\n/**\r\n * Get OMAI discovery status\r\n * GET /api/bigbook/omai/status\r\n */\r\nrouter.get('/omai/status', async (req, res) => {\r\n  try {\r\n    const status = await omaiDiscovery.getStatus();\r\n    \r\n    res.json({\r\n      success: true,\r\n      status: status,\r\n      timestamp: new Date().toISOString()\r\n    });\r\n  } catch (error) {\r\n    res.status(500).json({\r\n      success: false,\r\n      error: 'Failed to get OMAI discovery status',\r\n      details: error.message\r\n    });\r\n  }\r\n});\r\n\r\n/**\r\n * Get Big Book index\r\n * GET /api/bigbook/omai/index\r\n */\r\nrouter.get('/omai/index', async (req, res) => {\r\n  try {\r\n    const indexPath = path.join('/var/www/orthodox-church-mgmt/orthodoxmetrics/prod/bigbook', 'bigbook-index.json');\r\n    \r\n    try {\r\n      const indexContent = await fs.readFile(indexPath, 'utf8');\r\n      const index = JSON.parse(indexContent);\r\n      \r\n      res.json({\r\n        success: true,\r\n        index: index,\r\n        timestamp: new Date().toISOString()\r\n      });\r\n    } catch (error) {\r\n      if (error.code === 'ENOENT') {\r\n        res.json({\r\n          success: true,\r\n          index: null,\r\n          message: 'Big Book index not found. Run discovery first.',\r\n          timestamp: new Date().toISOString()\r\n        });\r\n      } else {\r\n        throw error;\r\n      }\r\n    }\r\n  } catch (error) {\r\n    res.status(500).json({\r\n      success: false,\r\n      error: 'Failed to get Big Book index',\r\n      details: error.message\r\n    });\r\n  }\r\n});\r\n\r\n/**\r\n * Get files by category\r\n * GET /api/bigbook/omai/category/:category\r\n */\r\nrouter.get('/omai/category/:category', async (req, res) => {\r\n  try {\r\n    const { category } = req.params;\r\n    const indexPath = path.join('/var/www/orthodox-church-mgmt/orthodoxmetrics/prod/bigbook', 'bigbook-index.json');\r\n    \r\n    const indexContent = await fs.readFile(indexPath, 'utf8');\r\n    const index = JSON.parse(indexContent);\r\n    \r\n    const categoryKey = Object.keys(index.categories).find(key => \r\n      key.toLowerCase().replace(/[^a-z0-9]/g, '_') === category.toLowerCase()\r\n    );\r\n    \r\n    if (!categoryKey) {\r\n      return res.status(404).json({\r\n        success: false,\r\n        error: 'Category not found',\r\n        availableCategories: Object.keys(index.categories)\r\n      });\r\n    }\r\n    \r\n    const categoryData = index.categories[categoryKey];\r\n    \r\n    res.json({\r\n      success: true,\r\n      category: categoryKey,\r\n      files: categoryData.files,\r\n      count: categoryData.count,\r\n      timestamp: new Date().toISOString()\r\n    });\r\n  } catch (error) {\r\n    res.status(500).json({\r\n      success: false,\r\n      error: 'Failed to get category files',\r\n      details: error.message\r\n    });\r\n  }\r\n});\r\n\r\n/**\r\n * Get file metadata\r\n * GET /api/bigbook/omai/file/:fileId\r\n */\r\nrouter.get('/omai/file/:fileId', async (req, res) => {\r\n  try {\r\n    const { fileId } = req.params;\r\n    const metadataPath = path.join('/var/www/orthodox-church-mgmt/orthodoxmetrics/prod/bigbook/metadata', `${fileId}.json`);\r\n    \r\n    const metadataContent = await fs.readFile(metadataPath, 'utf8');\r\n    const metadata = JSON.parse(metadataContent);\r\n    \r\n    res.json({\r\n      success: true,\r\n      file: metadata,\r\n      timestamp: new Date().toISOString()\r\n    });\r\n  } catch (error) {\r\n    if (error.code === 'ENOENT') {\r\n      res.status(404).json({\r\n        success: false,\r\n        error: 'File metadata not found'\r\n      });\r\n    } else {\r\n      res.status(500).json({\r\n        success: false,\r\n        error: 'Failed to get file metadata',\r\n        details: error.message\r\n      });\r\n    }\r\n  }\r\n});\r\n\r\n/**\r\n * Read file content (with security redaction)\r\n * GET /api/bigbook/omai/file/:fileId/content\r\n */\r\nrouter.get('/omai/file/:fileId/content', async (req, res) => {\r\n  try {\r\n    const { fileId } = req.params;\r\n    const metadataPath = path.join('/var/www/orthodox-church-mgmt/orthodoxmetrics/prod/bigbook/metadata', `${fileId}.json`);\r\n    \r\n    // Get file metadata\r\n    const metadataContent = await fs.readFile(metadataPath, 'utf8');\r\n    const metadata = JSON.parse(metadataContent);\r\n    \r\n    // Read original file content\r\n    let content = await fs.readFile(metadata.originalPath, 'utf8');\r\n    \r\n    // Apply security redaction if needed\r\n    if (metadata.metadata.security.hasSecurityIssues && metadata.metadata.security.redactedContent) {\r\n      content = metadata.metadata.security.redactedContent;\r\n    }\r\n    \r\n    res.json({\r\n      success: true,\r\n      fileId: fileId,\r\n      fileName: metadata.name,\r\n      content: content,\r\n      securityRedacted: metadata.metadata.security.hasSecurityIssues,\r\n      timestamp: new Date().toISOString()\r\n    });\r\n  } catch (error) {\r\n    if (error.code === 'ENOENT') {\r\n      res.status(404).json({\r\n        success: false,\r\n        error: 'File not found'\r\n      });\r\n    } else {\r\n      res.status(500).json({\r\n        success: false,\r\n        error: 'Failed to read file content',\r\n        details: error.message\r\n      });\r\n    }\r\n  }\r\n});\r\n\r\n/**\r\n * Schedule periodic discovery\r\n * POST /api/bigbook/omai/schedule\r\n */\r\nrouter.post('/omai/schedule', async (req, res) => {\r\n  try {\r\n    const { intervalHours = 24 } = req.body;\r\n    \r\n    await logToFile('execution.log', `OMAI periodic discovery scheduled for every ${intervalHours} hours`);\r\n    \r\n    // Schedule discovery (this would be better handled by a background service)\r\n    omaiDiscovery.scheduleDiscovery(intervalHours).catch(error => {\r\n      logToFile('execution.log', `OMAI scheduled discovery error: ${error.message}`);\r\n    });\r\n    \r\n    res.json({\r\n      success: true,\r\n      message: `OMAI discovery scheduled every ${intervalHours} hours`,\r\n      intervalHours: intervalHours,\r\n      timestamp: new Date().toISOString()\r\n    });\r\n  } catch (error) {\r\n    await logToFile('execution.log', `OMAI discovery scheduling failed: ${error.message}`);\r\n    res.status(500).json({\r\n      success: false,\r\n      error: 'Failed to schedule OMAI discovery',\r\n      details: error.message\r\n    });\r\n  }\r\n});\r\n\r\n/**\r\n * Get discovery summary\r\n * GET /api/bigbook/omai/summary\r\n */\r\nrouter.get('/omai/summary', async (req, res) => {\r\n  try {\r\n    const summaryPath = path.join('/var/www/orthodox-church-mgmt/orthodoxmetrics/prod/bigbook', 'discovery-summary.json');\r\n    \r\n    try {\r\n      const summaryContent = await fs.readFile(summaryPath, 'utf8');\r\n      const summary = JSON.parse(summaryContent);\r\n      \r\n      res.json({\r\n        success: true,\r\n        summary: summary,\r\n        timestamp: new Date().toISOString()\r\n      });\r\n    } catch (error) {\r\n      if (error.code === 'ENOENT') {\r\n        res.json({\r\n          success: true,\r\n          summary: null,\r\n          message: 'Discovery summary not found. Run discovery first.',\r\n          timestamp: new Date().toISOString()\r\n        });\r\n      } else {\r\n        throw error;\r\n      }\r\n    }\r\n  } catch (error) {\r\n    res.status(500).json({\r\n      success: false,\r\n      error: 'Failed to get discovery summary',\r\n      details: error.message\r\n    });\r\n  }\r\n});\r\n\r\n// =====================================================\r\n// PARISH MAP AUTO-INSTALL SYSTEM\r\n// =====================================================\r\n\r\nconst multer = require('multer');\r\nconst AdmZip = require('adm-zip');\r\nconst { authMiddleware: authenticate, requireRole: authorize } = require('../middleware/auth');\r\n\r\n// Configure multer for zip file uploads\r\nconst upload = multer({\r\n  dest: path.join(TEMP_DIR, 'uploads'),\r\n  limits: {\r\n    fileSize: 50 * 1024 * 1024 // 50MB limit\r\n  },\r\n  fileFilter: (req, file, cb) => {\r\n    // Only allow zip files\r\n    if (file.mimetype === 'application/zip' || \r\n        file.mimetype === 'application/x-zip-compressed' ||\r\n        path.extname(file.originalname).toLowerCase() === '.zip') {\r\n      cb(null, true);\r\n    } else {\r\n      cb(new Error('Only .zip files are allowed'), false);\r\n    }\r\n  }\r\n});\r\n\r\n/**\r\n * Upload and auto-install Parish Map component\r\n * POST /api/bigbook/upload-parish-map\r\n */\r\nrouter.post('/upload-parish-map', authenticate, authorize(['super_admin']), upload.single('parishMapZip'), async (req, res) => {\r\n  let tempFilePath = null;\r\n  let extractPath = null;\r\n  \r\n  try {\r\n    await ensureDirectories();\r\n    \r\n    if (!req.file) {\r\n      return res.status(400).json({\r\n        success: false,\r\n        error: 'No zip file uploaded'\r\n      });\r\n    }\r\n    \r\n    tempFilePath = req.file.path;\r\n    const originalName = req.file.originalname;\r\n    \r\n    await logToFile('parish-map.log', `Parish Map zip upload started: ${originalName} by ${req.user?.username || 'unknown'}`);\r\n    \r\n    // Security check: Validate file is actually a zip\r\n    if (!originalName.toLowerCase().endsWith('.zip')) {\r\n      throw new Error('File must have .zip extension');\r\n    }\r\n    \r\n    // Extract zip file\r\n    const zip = new AdmZip(tempFilePath);\r\n    const zipEntries = zip.getEntries();\r\n    \r\n    // Validate zip contents\r\n    const validation = validateParishMapZip(zipEntries);\r\n    if (!validation.isValid) {\r\n      throw new Error(`Invalid Parish Map zip: ${validation.errors.join(', ')}`);\r\n    }\r\n    \r\n    // Extract to target directory (use development-friendly path)\r\n    const addonsBaseDir = process.env.[REDACTED] === 'production' \r\n      ? '/var/www/orthodoxmetrics/addons' \r\n      : path.join(__dirname, '../../public/addons');\r\n    \r\n    extractPath = path.join(addonsBaseDir, 'parish-map');\r\n    await fs.mkdir(extractPath, { recursive: true });\r\n    \r\n    // Security check: Prevent path traversal during extraction\r\n    for (const entry of zipEntries) {\r\n      const entryPath = entry.entryName;\r\n      \r\n      // Check for path traversal attempts\r\n      if (entryPath.includes('..') || \r\n          entryPath.includes('/') && !entryPath.startsWith('parish-map/') ||\r\n          path.isAbsolute(entryPath)) {\r\n        throw new Error(`Suspicious file path detected: ${entryPath}`);\r\n      }\r\n      \r\n      // Extract file safely\r\n      const targetPath = path.join(extractPath, path.basename(entryPath));\r\n      const content = entry.getData();\r\n      \r\n      // Create subdirectories if needed\r\n      if (entryPath.includes('/')) {\r\n        const dirPath = path.dirname(targetPath);\r\n        await fs.mkdir(dirPath, { recursive: true });\r\n      }\r\n      \r\n      await fs.writeFile(targetPath, content);\r\n    }\r\n    \r\n    await logToFile('parish-map.log', `Parish Map extracted to: ${extractPath}`);\r\n    \r\n    // Validate extracted content\r\n    const extractedValidation = await validateExtractedParishMap(extractPath);\r\n    if (!extractedValidation.isValid) {\r\n      throw new Error(`Extracted content validation failed: ${extractedValidation.errors.join(', ')}`);\r\n    }\r\n    \r\n    // Read package.json for metadata\r\n    const packageJsonPath = path.join(extractPath, 'package.json');\r\n    let packageInfo = {};\r\n    try {\r\n      const packageContent = await fs.readFile(packageJsonPath, 'utf8');\r\n      packageInfo = JSON.parse(packageContent);\r\n    } catch (error) {\r\n      await logToFile('parish-map.log', `Warning: Could not read package.json: ${error.message}`);\r\n    }\r\n    \r\n    // Update addons configuration (flexible paths for dev/prod)\r\n    const configsBaseDir = process.env.[REDACTED] === 'production' \r\n      ? '/var/www/orthodox-church-mgmt/orthodoxmetrics/prod/configs' \r\n      : path.join(__dirname, '../../configs');\r\n    \r\n    const addonsConfigPath = path.join(configsBaseDir, 'addons.json');\r\n    const addonConfig = {\r\n      component: 'ParishMap',\r\n      entry: '/addons/parish-map/index.js',\r\n      displayName: packageInfo.displayName || 'Orthodox Parish Map',\r\n      description: packageInfo.description || 'Interactive parish mapping component',\r\n      version: packageInfo.version || '1.0.0',\r\n      route: '/addons/parish-map',\r\n      showInMenu: true,\r\n      installedAt: new Date().toISOString(),\r\n      installedBy: req.user?.username || 'admin'\r\n    };\r\n    \r\n    // Ensure configs directory exists\r\n    await fs.mkdir(configsBaseDir, { recursive: true });\r\n    await updateAddonsConfig(addonsConfigPath, 'parish-map', addonConfig);\r\n    await logToFile('parish-map.log', `Addon configuration updated: ${addonsConfigPath}`);\r\n    \r\n    // Update Big Book Components Index (flexible paths for dev/prod)\r\n    const bigbookBaseDir = process.env.[REDACTED] === 'production' \r\n      ? '/var/www/orthodox-church-mgmt/orthodoxmetrics/prod/bigbook' \r\n      : path.join(__dirname, '../../bigbook');\r\n    \r\n    const indexPath = path.join(bigbookBaseDir, 'BIG_BOOK_COMPONENTS_INDEX.md');\r\n    \r\n    // Ensure bigbook directory exists\r\n    await fs.mkdir(bigbookBaseDir, { recursive: true });\r\n    await updateBigBookIndex(indexPath, addonConfig);\r\n    await logToFile('parish-map.log', `Big Book index updated: ${indexPath}`);\r\n    \r\n    // Clean up temp file\r\n    if (tempFilePath) {\r\n      await fs.unlink(tempFilePath);\r\n    }\r\n    \r\n    await logToFile('parish-map.log', `Parish Map installation completed successfully`);\r\n    \r\n    res.json({\r\n      success: true,\r\n      message: 'Parish Map installed successfully',\r\n      addon: addonConfig,\r\n      extractPath: extractPath,\r\n      files: zipEntries.map(entry => entry.entryName),\r\n      timestamp: new Date().toISOString()\r\n    });\r\n    \r\n  } catch (error) {\r\n    console.error('Parish Map installation error:', error);\r\n    await logToFile('parish-map.log', `Installation error: ${error.message}`);\r\n    \r\n    // Clean up on error\r\n    try {\r\n      if (tempFilePath) {\r\n        await fs.unlink(tempFilePath);\r\n      }\r\n      if (extractPath && await fs.access(extractPath).then(() => true).catch(() => false)) {\r\n        await fs.rmdir(extractPath, { recursive: true });\r\n      }\r\n    } catch (cleanupError) {\r\n      await logToFile('parish-map.log', `Cleanup error: ${cleanupError.message}`);\r\n    }\r\n    \r\n    res.status(500).json({\r\n      success: false,\r\n      error: error.message || 'Parish Map installation failed'\r\n    });\r\n  }\r\n});\r\n\r\n/**\r\n * Validate Parish Map zip contents\r\n */\r\nfunction validateParishMapZip(zipEntries) {\r\n  const validation = {\r\n    isValid: false,\r\n    errors: [],\r\n    warnings: []\r\n  };\r\n  \r\n  const requiredFiles = ['index.js', 'package.json'];\r\n  const foundFiles = zipEntries.map(entry => path.basename(entry.entryName));\r\n  \r\n  // Check for required files\r\n  for (const required of requiredFiles) {\r\n    if (!foundFiles.includes(required)) {\r\n      validation.errors.push(`Missing required file: ${required}`);\r\n    }\r\n  }\r\n  \r\n  // Check for suspicious files\r\n  for (const entry of zipEntries) {\r\n    const fileName = entry.entryName.toLowerCase();\r\n    \r\n    // Check for executable files\r\n    if (fileName.endsWith('.exe') || fileName.endsWith('.sh') || fileName.endsWith('.bat')) {\r\n      validation.errors.push(`Executable files not allowed: ${entry.entryName}`);\r\n    }\r\n    \r\n    // Check for hidden files (except common ones)\r\n    if (fileName.startsWith('.') && \r\n        !fileName.startsWith('.git') && \r\n        !fileName.startsWith('.npm')) {\r\n      validation.warnings.push(`Hidden file detected: ${entry.entryName}`);\r\n    }\r\n  }\r\n  \r\n  validation.isValid = validation.errors.length === 0;\r\n  return validation;\r\n}\r\n\r\n/**\r\n * Validate extracted Parish Map content\r\n */\r\nasync function validateExtractedParishMap(extractPath) {\r\n  const validation = {\r\n    isValid: false,\r\n    errors: [],\r\n    warnings: []\r\n  };\r\n  \r\n  try {\r\n    // Check index.js exists and is valid\r\n    const indexPath = path.join(extractPath, 'index.js');\r\n    if (await fs.access(indexPath).then(() => true).catch(() => false)) {\r\n      const indexContent = await fs.readFile(indexPath, 'utf8');\r\n      \r\n      // Basic React component validation\r\n      if (!indexContent.includes('React') && !indexContent.includes('export')) {\r\n        validation.warnings.push('index.js may not be a valid React component');\r\n      }\r\n    } else {\r\n      validation.errors.push('index.js not found after extraction');\r\n    }\r\n    \r\n    // Check package.json\r\n    const packagePath = path.join(extractPath, 'package.json');\r\n    if (await fs.access(packagePath).then(() => true).catch(() => false)) {\r\n      try {\r\n        const packageContent = await fs.readFile(packagePath, 'utf8');\r\n        JSON.parse(packageContent); // Validate JSON\r\n      } catch (error) {\r\n        validation.errors.push('package.json is not valid JSON');\r\n      }\r\n    } else {\r\n      validation.warnings.push('package.json not found');\r\n    }\r\n    \r\n    validation.isValid = validation.errors.length === 0;\r\n    \r\n  } catch (error) {\r\n    validation.errors.push(`Validation error: ${error.message}`);\r\n  }\r\n  \r\n  return validation;\r\n}\r\n\r\n/**\r\n * Update addons configuration file\r\n */\r\nasync function updateAddonsConfig(configPath, addonId, addonConfig) {\r\n  try {\r\n    // Ensure config directory exists\r\n    await fs.mkdir(path.dirname(configPath), { recursive: true });\r\n    \r\n    let addonsConfig = {};\r\n    \r\n    // Read existing config if it exists\r\n    try {\r\n      const configContent = await fs.readFile(configPath, 'utf8');\r\n      addonsConfig = JSON.parse(configContent);\r\n    } catch (error) {\r\n      // Create new config if file doesn't exist\r\n      addonsConfig = {\r\n        version: '1.0.0',\r\n        lastUpdated: new Date().toISOString(),\r\n        addons: {}\r\n      };\r\n    }\r\n    \r\n    // Add/update addon\r\n    addonsConfig.addons[addonId] = addonConfig;\r\n    addonsConfig.lastUpdated = new Date().toISOString();\r\n    \r\n    // Write updated config\r\n    await fs.writeFile(configPath, JSON.stringify(addonsConfig, null, 2));\r\n    \r\n  } catch (error) {\r\n    throw new Error(`Failed to update addons config: ${error.message}`);\r\n  }\r\n}\r\n\r\n/**\r\n * Update Big Book Components Index\r\n */\r\nasync function updateBigBookIndex(indexPath, addonConfig) {\r\n  try {\r\n    // Ensure directory exists\r\n    await fs.mkdir(path.dirname(indexPath), { recursive: true });\r\n    \r\n    let indexContent = '';\r\n    \r\n    // Read existing index if it exists\r\n    try {\r\n      indexContent = await fs.readFile(indexPath, 'utf8');\r\n    } catch (error) {\r\n      // Create new index if file doesn't exist\r\n      indexContent = `# Big Book Components Index\r\n\r\nThis file contains links to all installed components and addons.\r\n\r\n## Auto-Installed Components\r\n\r\n`;\r\n    }\r\n    \r\n    // Create markdown link for the new component\r\n    const markdownLink = `[ ${addonConfig.displayName}](${addonConfig.route})`;\r\n    const linkLine = `${markdownLink} - ${addonConfig.description || 'No description'}`;\r\n    \r\n    // Check if component link already exists\r\n    if (!indexContent.includes(markdownLink)) {\r\n      // Add to Auto-Installed Components section\r\n      const sectionMarker = '## Auto-Installed Components';\r\n      if (indexContent.includes(sectionMarker)) {\r\n        indexContent = indexContent.replace(\r\n          sectionMarker,\r\n          `${sectionMarker}\\n\\n${linkLine}`\r\n        );\r\n      } else {\r\n        indexContent += `\\n\\n## Auto-Installed Components\\n\\n${linkLine}`;\r\n      }\r\n    }\r\n    \r\n    // Write updated index\r\n    await fs.writeFile(indexPath, indexContent);\r\n    \r\n  } catch (error) {\r\n    throw new Error(`Failed to update Big Book index: ${error.message}`);\r\n  }\r\n}\r\n\r\n/**\r\n * Get installed addons\r\n * GET /api/bigbook/addons\r\n */\r\nrouter.get('/addons', authenticate, authorize(['admin', 'super_admin']), async (req, res) => {\r\n  try {\r\n    const addonsConfigPath = '/var/www/orthodox-church-mgmt/orthodoxmetrics/prod/configs/addons.json';\r\n    \r\n    try {\r\n      const configContent = await fs.readFile(addonsConfigPath, 'utf8');\r\n      const addonsConfig = JSON.parse(configContent);\r\n      \r\n      res.json({\r\n        success: true,\r\n        addons: addonsConfig.addons || {},\r\n        version: addonsConfig.version,\r\n        lastUpdated: addonsConfig.lastUpdated\r\n      });\r\n    } catch (error) {\r\n      if (error.code === 'ENOENT') {\r\n        res.json({\r\n          success: true,\r\n          addons: {},\r\n          message: 'No addons installed yet'\r\n        });\r\n      } else {\r\n        throw error;\r\n      }\r\n    }\r\n    \r\n  } catch (error) {\r\n    console.error('Get addons error:', error);\r\n    res.status(500).json({\r\n      success: false,\r\n      error: error.message || 'Failed to get addons'\r\n    });\r\n  }\r\n});\r\n\r\n/**\r\n * Uninstall addon\r\n * DELETE /api/bigbook/addons/:addonId\r\n */\r\nrouter.delete('/addons/:addonId', authenticate, authorize(['super_admin']), async (req, res) => {\r\n  try {\r\n    const { addonId } = req.params;\r\n    \r\n    await logToFile('parish-map.log', `Addon uninstall requested: ${addonId} by ${req.user?.username || 'unknown'}`);\r\n    \r\n    // Read current addons config\r\n    const addonsConfigPath = '/var/www/orthodox-church-mgmt/orthodoxmetrics/prod/configs/addons.json';\r\n    const configContent = await fs.readFile(addonsConfigPath, 'utf8');\r\n    const addonsConfig = JSON.parse(configContent);\r\n    \r\n    if (!addonsConfig.addons[addonId]) {\r\n      return res.status(404).json({\r\n        success: false,\r\n        error: 'Addon not found'\r\n      });\r\n    }\r\n    \r\n    const addonConfig = addonsConfig.addons[addonId];\r\n    \r\n    // Remove addon files\r\n    const addonPath = `/var/www/orthodoxmetrics/addons/${addonId}`;\r\n    if (await fs.access(addonPath).then(() => true).catch(() => false)) {\r\n      await fs.rmdir(addonPath, { recursive: true });\r\n      await logToFile('parish-map.log', `Addon files removed: ${addonPath}`);\r\n    }\r\n    \r\n    // Update config\r\n    delete addonsConfig.addons[addonId];\r\n    addonsConfig.lastUpdated = new Date().toISOString();\r\n    await fs.writeFile(addonsConfigPath, JSON.stringify(addonsConfig, null, 2));\r\n    \r\n    await logToFile('parish-map.log', `Addon uninstalled successfully: ${addonId}`);\r\n    \r\n    res.json({\r\n      success: true,\r\n      message: `Addon '${addonConfig.displayName}' uninstalled successfully`,\r\n      uninstalledAddon: addonConfig\r\n    });\r\n    \r\n  } catch (error) {\r\n    console.error('Addon uninstall error:', error);\r\n    await logToFile('parish-map.log', `Uninstall error: ${error.message}`);\r\n    \r\n    res.status(500).json({\r\n      success: false,\r\n      error: error.message || 'Failed to uninstall addon'\r\n    });\r\n  }\r\n});\r\n\r\n// =====================================================\r\n// CENTRALIZED FILE INGESTION SYSTEM\r\n// =====================================================\r\n\r\n/**\r\n * Registry Management System\r\n * Handles all file type registries: addons, scripts, docs, configs\r\n */\r\nclass FileRegistryManager {\r\n  constructor() {\r\n    this.registryPaths = {\r\n      addons: this.getRegistryPath('addons.json'),\r\n      scripts: this.getRegistryPath('scripts.json'),\r\n      docs: this.getRegistryPath('docs.json'),\r\n      configs: this.getRegistryPath('configs.json'),\r\n      data: this.getRegistryPath('data.json')\r\n    };\r\n    \r\n    this.storagePaths = {\r\n      addons: this.getStoragePath('addons'),\r\n      scripts: this.getStoragePath('scripts'),\r\n      docs: this.getStoragePath('docs'),\r\n      configs: this.getStoragePath('configs'),\r\n      data: this.getStoragePath('data')\r\n    };\r\n  }\r\n  \r\n  getRegistryPath(filename) {\r\n    const configsBaseDir = process.env.[REDACTED] === 'production' \r\n      ? '/var/www/orthodox-church-mgmt/orthodoxmetrics/prod/configs' \r\n      : path.join(__dirname, '../../configs');\r\n    return path.join(configsBaseDir, filename);\r\n  }\r\n  \r\n  getStoragePath(type) {\r\n    const baseDir = process.env.[REDACTED] === 'production' \r\n      ? '/var/www/orthodoxmetrics' \r\n      : path.join(__dirname, '../../public');\r\n    \r\n    switch (type) {\r\n      case 'addons': return path.join(baseDir, 'addons');\r\n      case 'scripts': return path.join(baseDir, 'bigbook', 'scripts');\r\n      case 'docs': return path.join(baseDir, 'bigbook', 'docs');\r\n      case 'configs': return path.join(baseDir, 'bigbook', 'configs');\r\n      case 'data': return path.join(baseDir, 'bigbook', 'data');\r\n      default: throw new Error(`Unknown storage type: ${type}`);\r\n    }\r\n  }\r\n  \r\n  async ensureRegistryDirectories() {\r\n    for (const [type, storagePath] of Object.entries(this.storagePaths)) {\r\n      await fs.mkdir(storagePath, { recursive: true });\r\n    }\r\n    \r\n    // Ensure configs directory exists\r\n    const configsDir = path.dirname(this.registryPaths.addons);\r\n    await fs.mkdir(configsDir, { recursive: true });\r\n  }\r\n  \r\n  async loadRegistry(type) {\r\n    try {\r\n      const registryPath = this.registryPaths[type];\r\n      const content = await fs.readFile(registryPath, 'utf8');\r\n      return JSON.parse(content);\r\n    } catch (error) {\r\n      // Return empty registry if file doesn't exist\r\n      return { version: '1.0.0', lastUpdated: new Date().toISOString(), items: {} };\r\n    }\r\n  }\r\n  \r\n  async saveRegistry(type, registry) {\r\n    const registryPath = this.registryPaths[type];\r\n    registry.lastUpdated = new Date().toISOString();\r\n    registry.version = registry.version || '1.0.0';\r\n    \r\n    await fs.writeFile(registryPath, JSON.stringify(registry, null, 2));\r\n    await logToFile('registry.log', `Registry updated: ${type} -> ${registryPath}`);\r\n  }\r\n  \r\n  async addItem(type, id, item) {\r\n    const registry = await this.loadRegistry(type);\r\n    registry.items[id] = {\r\n      ...item,\r\n      id,\r\n      createdAt: new Date().toISOString(),\r\n      updatedAt: new Date().toISOString()\r\n    };\r\n    await this.saveRegistry(type, registry);\r\n    return registry.items[id];\r\n  }\r\n  \r\n  async updateItem(type, id, updates) {\r\n    const registry = await this.loadRegistry(type);\r\n    if (!registry.items[id]) {\r\n      throw new Error(`Item not found: ${id} in ${type} registry`);\r\n    }\r\n    \r\n    registry.items[id] = {\r\n      ...registry.items[id],\r\n      ...updates,\r\n      updatedAt: new Date().toISOString()\r\n    };\r\n    await this.saveRegistry(type, registry);\r\n    return registry.items[id];\r\n  }\r\n  \r\n  async removeItem(type, id) {\r\n    const registry = await this.loadRegistry(type);\r\n    if (registry.items[id]) {\r\n      delete registry.items[id];\r\n      await this.saveRegistry(type, registry);\r\n      return true;\r\n    }\r\n    return false;\r\n  }\r\n  \r\n  async getAllRegistries() {\r\n    const registries = {};\r\n    for (const type of Object.keys(this.registryPaths)) {\r\n      registries[type] = await this.loadRegistry(type);\r\n    }\r\n    return registries;\r\n  }\r\n}\r\n\r\n/**\r\n * File Type Processors\r\n * Handle specific processing logic for each file type\r\n */\r\nclass FileTypeProcessors {\r\n  constructor(registryManager) {\r\n    this.registry = registryManager;\r\n  }\r\n  \r\n  async processZipFile(file, tempPath) {\r\n    try {\r\n      // Detect zip type based on contents\r\n      const zip = new AdmZip(tempPath);\r\n      const entries = zip.getEntries();\r\n      \r\n      // Check if it's a Parish Map\r\n      if (this.isParishMapZip(entries)) {\r\n        return await this.processParishMapZip(file, tempPath);\r\n      }\r\n      \r\n      // Check if it's a component addon\r\n      if (this.isComponentZip(entries)) {\r\n        return await this.processComponentZip(file, tempPath);\r\n      }\r\n      \r\n      // Generic zip extraction\r\n      return await this.processGenericZip(file, tempPath);\r\n      \r\n    } catch (error) {\r\n      throw new Error(`ZIP processing failed: ${error.message}`);\r\n    }\r\n  }\r\n  \r\n  isParishMapZip(entries) {\r\n    return entries.some(entry => \r\n      entry.entryName.includes('parish-map') || \r\n      entry.entryName.includes('ParishMap')\r\n    );\r\n  }\r\n  \r\n  isComponentZip(entries) {\r\n    return entries.some(entry => \r\n      entry.entryName.endsWith('package.json') ||\r\n      entry.entryName.endsWith('index.js') ||\r\n      entry.entryName.endsWith('component.js')\r\n    );\r\n  }\r\n  \r\n  async processParishMapZip(file, tempPath) {\r\n    // Use existing Parish Map logic (simplified)\r\n    return {\r\n      type: 'addon',\r\n      category: 'parish-map',\r\n      message: 'Parish Map zip detected - use dedicated endpoint',\r\n      action: 'redirect',\r\n      endpoint: '/api/bigbook/upload-parish-map'\r\n    };\r\n  }\r\n  \r\n  async processComponentZip(file, tempPath) {\r\n    const zip = new AdmZip(tempPath);\r\n    const entries = zip.getEntries();\r\n    const fileId = uuidv4();\r\n    const componentName = path.basename(file.originalname, '.zip');\r\n    \r\n    // Extract to addons directory\r\n    const extractPath = path.join(this.registry.storagePaths.addons, componentName);\r\n    await fs.mkdir(extractPath, { recursive: true });\r\n    \r\n    // Extract files safely\r\n    for (const entry of entries) {\r\n      if (entry.entryName.includes('..') || path.isAbsolute(entry.entryName)) {\r\n        throw new Error(`Unsafe path detected: ${entry.entryName}`);\r\n      }\r\n      \r\n      const targetPath = path.join(extractPath, entry.entryName);\r\n      const targetDir = path.dirname(targetPath);\r\n      await fs.mkdir(targetDir, { recursive: true });\r\n      await fs.writeFile(targetPath, entry.getData());\r\n    }\r\n    \r\n    // Register component\r\n    const addonItem = {\r\n      name: componentName,\r\n      displayName: componentName.replace(/-/g, ' ').replace(/\\b\\w/g, l => l.toUpperCase()),\r\n      type: 'component',\r\n      source: 'zip-upload',\r\n      path: extractPath,\r\n      entry: `/addons/${componentName}/index.js`,\r\n      route: `/addons/${componentName}`,\r\n      enabled: true,\r\n      showInMenu: true\r\n    };\r\n    \r\n    await this.registry.addItem('addons', fileId, addonItem);\r\n    \r\n    return {\r\n      type: 'addon',\r\n      category: 'component',\r\n      id: fileId,\r\n      item: addonItem,\r\n      message: `Component '${componentName}' extracted and registered`\r\n    };\r\n  }\r\n  \r\n  async processGenericZip(file, tempPath) {\r\n    // Store in data directory for manual processing\r\n    const fileId = uuidv4();\r\n    const fileName = path.basename(file.originalname, '.zip');\r\n    const storagePath = path.join(this.registry.storagePaths.data, `${fileName}-${fileId}.zip`);\r\n    \r\n    await fs.copyFile(tempPath, storagePath);\r\n    \r\n    const dataItem = {\r\n      name: fileName,\r\n      originalName: file.originalname,\r\n      type: 'zip-archive',\r\n      storagePath,\r\n      size: file.size,\r\n      status: 'stored'\r\n    };\r\n    \r\n    await this.registry.addItem('data', fileId, dataItem);\r\n    \r\n    return {\r\n      type: 'data',\r\n      category: 'zip-archive',\r\n      id: fileId,\r\n      item: dataItem,\r\n      message: `ZIP archive '${fileName}' stored for manual processing`\r\n    };\r\n  }\r\n  \r\n  async processJsFile(file, content) {\r\n    const fileId = uuidv4();\r\n    const fileName = path.basename(file.originalname, '.js');\r\n    const storagePath = path.join(this.registry.storagePaths.addons, `${fileName}.js`);\r\n    \r\n    // Security check: Basic JS validation\r\n    if (content.includes('eval(') || content.includes('Function(')) {\r\n      throw new Error('JavaScript file contains potentially unsafe code');\r\n    }\r\n    \r\n    await fs.writeFile(storagePath, content);\r\n    \r\n    const addonItem = {\r\n      name: fileName,\r\n      displayName: fileName.replace(/-/g, ' ').replace(/\\b\\w/g, l => l.toUpperCase()),\r\n      type: 'javascript-module',\r\n      source: 'direct-upload',\r\n      path: storagePath,\r\n      entry: `/addons/${fileName}.js`,\r\n      enabled: false, // Require manual enable for JS files\r\n      showInMenu: false\r\n    };\r\n    \r\n    await this.registry.addItem('addons', fileId, addonItem);\r\n    \r\n    return {\r\n      type: 'addon',\r\n      category: 'javascript-module',\r\n      id: fileId,\r\n      item: addonItem,\r\n      message: `JavaScript module '${fileName}' uploaded (requires manual enable)`\r\n    };\r\n  }\r\n  \r\n  async processJsonFile(file, content) {\r\n    const fileId = uuidv4();\r\n    const fileName = path.basename(file.originalname, '.json');\r\n    const storagePath = path.join(this.registry.storagePaths.configs, file.originalname);\r\n    \r\n    // Validate JSON\r\n    try {\r\n      JSON.parse(content);\r\n    } catch (error) {\r\n      throw new Error(`Invalid JSON format: ${error.message}`);\r\n    }\r\n    \r\n    await fs.writeFile(storagePath, content);\r\n    \r\n    const configItem = {\r\n      name: fileName,\r\n      originalName: file.originalname,\r\n      type: 'json-config',\r\n      storagePath,\r\n      size: file.size,\r\n      status: 'active'\r\n    };\r\n    \r\n    await this.registry.addItem('configs', fileId, configItem);\r\n    \r\n    return {\r\n      type: 'config',\r\n      category: 'json-config',\r\n      id: fileId,\r\n      item: configItem,\r\n      message: `JSON configuration '${fileName}' stored`\r\n    };\r\n  }\r\n  \r\n  async processMarkdownFile(file, content) {\r\n    const fileId = uuidv4();\r\n    const fileName = path.basename(file.originalname, '.md');\r\n    const storagePath = path.join(this.registry.storagePaths.docs, file.originalname);\r\n    \r\n    await fs.writeFile(storagePath, content);\r\n    \r\n    // Extract title from markdown\r\n    const titleMatch = content.match(/^#\\s+(.+)$/m);\r\n    const title = titleMatch ? titleMatch[1] : fileName;\r\n    \r\n    const docItem = {\r\n      name: fileName,\r\n      title,\r\n      originalName: file.originalname,\r\n      type: 'markdown-doc',\r\n      storagePath,\r\n      size: file.size,\r\n      webPath: `/bigbook/docs/${file.originalname}`,\r\n      tags: this.extractMarkdownTags(content)\r\n    };\r\n    \r\n    await this.registry.addItem('docs', fileId, docItem);\r\n    \r\n    return {\r\n      type: 'doc',\r\n      category: 'markdown-doc',\r\n      id: fileId,\r\n      item: docItem,\r\n      message: `Markdown document '${title}' stored`\r\n    };\r\n  }\r\n  \r\n  async processShellScript(file, content) {\r\n    const fileId = uuidv4();\r\n    const fileName = path.basename(file.originalname, '.sh');\r\n    const storagePath = path.join(this.registry.storagePaths.scripts, file.originalname);\r\n    \r\n    // Security check: Basic shell script validation\r\n    const dangerousPatterns = ['rm -rf /', 'sudo rm', 'mkfs', 'dd if=', '> /dev/'];\r\n    for (const pattern of dangerousPatterns) {\r\n      if (content.includes(pattern)) {\r\n        throw new Error(`Shell script contains potentially dangerous command: ${pattern}`);\r\n      }\r\n    }\r\n    \r\n    await fs.writeFile(storagePath, content);\r\n    \r\n    // Make executable (on Unix systems)\r\n    try {\r\n      await fs.chmod(storagePath, '755');\r\n    } catch (error) {\r\n      // Ignore chmod errors on Windows\r\n    }\r\n    \r\n    const scriptItem = {\r\n      name: fileName,\r\n      originalName: file.originalname,\r\n      type: 'shell-script',\r\n      storagePath,\r\n      size: file.size,\r\n      executable: true,\r\n      enabled: false // Require manual enable for scripts\r\n    };\r\n    \r\n    await this.registry.addItem('scripts', fileId, scriptItem);\r\n    \r\n    return {\r\n      type: 'script',\r\n      category: 'shell-script',\r\n      id: fileId,\r\n      item: scriptItem,\r\n      message: `Shell script '${fileName}' stored (requires manual enable)`\r\n    };\r\n  }\r\n  \r\n  extractMarkdownTags(content) {\r\n    const tags = [];\r\n    const tagMatches = content.match(/\\[([^\\]]+)\\]/g);\r\n    if (tagMatches) {\r\n      tags.push(...tagMatches.map(match => match.slice(1, -1)));\r\n    }\r\n    return tags;\r\n  }\r\n}\r\n\r\n// Initialize registry manager and processors\r\nconst registryManager = new FileRegistryManager();\r\nconst fileProcessors = new FileTypeProcessors(registryManager);\r\n\r\n// Configure multer for multiple file types\r\nconst uploadMultiType = multer({\r\n  dest: path.join(TEMP_DIR, 'uploads'),\r\n  limits: {\r\n    fileSize: 100 * 1024 * 1024 // 100MB limit\r\n  },\r\n  fileFilter: (req, file, cb) => {\r\n    const allowedExtensions = ['.zip', '.js', '.json', '.md', '.sh'];\r\n    const ext = path.extname(file.originalname).toLowerCase();\r\n    \r\n    // Explicitly reject .tsx files (they should use the TSX component wizard)\r\n    if (ext === '.tsx') {\r\n      cb(new Error('TSX files must be processed through the TSX Component Installation Wizard'), false);\r\n      return;\r\n    }\r\n    \r\n    if (allowedExtensions.includes(ext)) {\r\n      cb(null, true);\r\n    } else {\r\n      cb(new Error(`File type not supported. Allowed: ${allowedExtensions.join(', ')}`), false);\r\n    }\r\n  }\r\n});\r\n\r\n/**\r\n * Centralized File Ingestion Endpoint\r\n * POST /api/bigbook/ingest-file\r\n */\r\nrouter.post('/ingest-file', authenticate, authorize(['super_admin']), uploadMultiType.single('file'), async (req, res) => {\r\n  let tempFilePath = null;\r\n  \r\n  try {\r\n    await registryManager.ensureRegistryDirectories();\r\n    \r\n    if (!req.file) {\r\n      return res.status(400).json({\r\n        success: false,\r\n        error: 'No file uploaded'\r\n      });\r\n    }\r\n    \r\n    tempFilePath = req.file.path;\r\n    const originalName = req.file.originalname;\r\n    const extension = path.extname(originalName).toLowerCase();\r\n    \r\n    await logToFile('ingestion.log', `File ingestion started: ${originalName} by ${req.user?.username || 'unknown'}`);\r\n    \r\n    let result;\r\n    \r\n    switch (extension) {\r\n      case '.zip':\r\n        result = await fileProcessors.processZipFile(req.file, tempFilePath);\r\n        break;\r\n      case '.js':\r\n        const jsContent = await fs.readFile(tempFilePath, 'utf8');\r\n        result = await fileProcessors.processJsFile(req.file, jsContent);\r\n        break;\r\n      case '.json':\r\n        const jsonContent = await fs.readFile(tempFilePath, 'utf8');\r\n        result = await fileProcessors.processJsonFile(req.file, jsonContent);\r\n        break;\r\n      case '.md':\r\n        const mdContent = await fs.readFile(tempFilePath, 'utf8');\r\n        result = await fileProcessors.processMarkdownFile(req.file, mdContent);\r\n        break;\r\n      case '.sh':\r\n        const shContent = await fs.readFile(tempFilePath, 'utf8');\r\n        result = await fileProcessors.processShellScript(req.file, shContent);\r\n        break;\r\n      default:\r\n        throw new Error(`Unsupported file type: ${extension}`);\r\n    }\r\n    \r\n    await logToFile('ingestion.log', `File processed successfully: ${originalName} -> ${result.type}/${result.category}`);\r\n    \r\n    // Optionally notify OMAI for learning (if enabled)\r\n    if (req.body.notifyOMAI === 'true') {\r\n      try {\r\n        await notifyOMAIForLearning(result);\r\n      } catch (error) {\r\n        await logToFile('ingestion.log', `OMAI notification failed: ${error.message}`);\r\n      }\r\n    }\r\n    \r\n    res.json({\r\n      success: true,\r\n      result,\r\n      registries: await registryManager.getAllRegistries()\r\n    });\r\n    \r\n  } catch (error) {\r\n    await logToFile('ingestion.log', `File ingestion failed: ${req.file?.originalname || 'unknown'} - ${error.message}`);\r\n    \r\n    res.status(500).json({\r\n      success: false,\r\n      error: error.message,\r\n      debug: {\r\n        file: req.file?.originalname,\r\n        size: req.file?.size,\r\n        mimetype: req.file?.mimetype\r\n      }\r\n    });\r\n  } finally {\r\n    // Clean up temp file\r\n    if (tempFilePath) {\r\n      try {\r\n        await fs.unlink(tempFilePath);\r\n      } catch (error) {\r\n        // Ignore cleanup errors\r\n      }\r\n    }\r\n  }\r\n});\r\n\r\n/**\r\n * Get All Registries\r\n * GET /api/bigbook/registries\r\n */\r\nrouter.get('/registries', authenticate, authorize(['super_admin']), async (req, res) => {\r\n  try {\r\n    const registries = await registryManager.getAllRegistries();\r\n    res.json({\r\n      success: true,\r\n      registries\r\n    });\r\n  } catch (error) {\r\n    res.status(500).json({\r\n      success: false,\r\n      error: error.message\r\n    });\r\n  }\r\n});\r\n\r\n/**\r\n * Toggle Item Status\r\n * POST /api/bigbook/toggle-item/:type/:id\r\n */\r\nrouter.post('/toggle-item/:type/:id', authenticate, authorize(['super_admin']), async (req, res) => {\r\n  try {\r\n    const { type, id } = req.params;\r\n    const { enabled } = req.body;\r\n    \r\n    if (!registryManager.registryPaths[type]) {\r\n      return res.status(400).json({\r\n        success: false,\r\n        error: `Invalid registry type: ${type}`\r\n      });\r\n    }\r\n    \r\n    const updatedItem = await registryManager.updateItem(type, id, { enabled });\r\n    \r\n    await logToFile('registry.log', `Item toggled: ${type}/${id} -> enabled: ${enabled}`);\r\n    \r\n    res.json({\r\n      success: true,\r\n      item: updatedItem\r\n    });\r\n  } catch (error) {\r\n    res.status(500).json({\r\n      success: false,\r\n      error: error.message\r\n    });\r\n  }\r\n});\r\n\r\n/**\r\n * OMAI Learning Notification\r\n */\r\nasync function notifyOMAIForLearning(result) {\r\n  try {\r\n    await logToFile('omai-learning.log', `OMAI Learning Notification: ${JSON.stringify(result, null, 2)}`);\r\n    \r\n    // Connect to OMAI orchestrator for learning ingestion\r\n    const { OMAIOrchestrator } = require('../../services/om-ai/orchestrator');\r\n    \r\n    // Initialize orchestrator if needed\r\n    let orchestrator;\r\n    try {\r\n      orchestrator = new OMAIOrchestrator();\r\n    } catch (error) {\r\n      await logToFile('omai-learning.log', `OMAI Orchestrator initialization failed: ${error.message}`);\r\n      return false;\r\n    }\r\n    \r\n    // Prepare content for OMAI ingestion\r\n    const content = await prepareContentForOMAI(result);\r\n    const metadata = await prepareMetadataForOMAI(result);\r\n    \r\n    // Ingest into OMAI memory\r\n    await orchestrator.omaiMemoryIngest(content, metadata);\r\n    \r\n    await logToFile('omai-learning.log', `OMAI ingestion successful for: ${result.item?.name || result.id}`);\r\n    return true;\r\n    \r\n  } catch (error) {\r\n    await logToFile('omai-learning.log', `OMAI ingestion failed: ${error.message}`);\r\n    return false;\r\n  }\r\n}\r\n\r\n/**\r\n * Prepare content for OMAI ingestion\r\n */\r\nasync function prepareContentForOMAI(result) {\r\n  try {\r\n    const { item, type, category } = result;\r\n    \r\n    let content = '';\r\n    let sections = [];\r\n    \r\n    switch (type) {\r\n      case 'doc':\r\n        // For markdown documents, read the file content\r\n        if (item.storagePath) {\r\n          try {\r\n            content = await fs.readFile(item.storagePath, 'utf8');\r\n            \r\n            // Extract sections from markdown\r\n            const lines = content.split('\\n');\r\n            let currentSection = '';\r\n            let currentContent = '';\r\n            \r\n            for (const line of lines) {\r\n              if (line.startsWith('#')) {\r\n                if (currentSection && currentContent) {\r\n                  sections.push({\r\n                    title: currentSection,\r\n                    content: currentContent.trim()\r\n                  });\r\n                }\r\n                currentSection = line.replace(/^#+\\s*/, '');\r\n                currentContent = '';\r\n              } else {\r\n                currentContent += line + '\\n';\r\n              }\r\n            }\r\n            \r\n            // Add last section\r\n            if (currentSection && currentContent) {\r\n              sections.push({\r\n                title: currentSection,\r\n                content: currentContent.trim()\r\n              });\r\n            }\r\n          } catch (error) {\r\n            content = `Document: ${item.title || item.name}\\nDescription: ${item.description || 'No description available'}`;\r\n          }\r\n        }\r\n        break;\r\n        \r\n      case 'addon':\r\n        // For addons, create descriptive content\r\n        content = `Component: ${item.displayName || item.name}\r\nType: ${item.type}\r\nRoute: ${item.route || 'N/A'}\r\nEntry Point: ${item.entry || 'N/A'}\r\nDescription: ${item.description || 'Interactive component'}\r\nSource: ${item.source}\r\nStatus: ${item.enabled ? 'Enabled' : 'Disabled'}`;\r\n        \r\n        sections = [\r\n          {\r\n            title: 'Component Information',\r\n            content: `Name: ${item.displayName || item.name}\\nType: ${item.type}\\nRoute: ${item.route}`\r\n          },\r\n          {\r\n            title: 'Technical Details',\r\n            content: `Entry: ${item.entry}\\nSource: ${item.source}\\nEnabled: ${item.enabled}`\r\n          }\r\n        ];\r\n        break;\r\n        \r\n      case 'script':\r\n        // For scripts, read the content if possible\r\n        content = `Script: ${item.name}\r\nType: ${item.type}\r\nExecutable: ${item.executable}\r\nPath: ${item.storagePath}\r\nStatus: ${item.enabled ? 'Enabled' : 'Disabled'}`;\r\n        \r\n        if (item.storagePath) {\r\n          try {\r\n            const scriptContent = await fs.readFile(item.storagePath, 'utf8');\r\n            content += `\\n\\nScript Content:\\n${scriptContent}`;\r\n          } catch (error) {\r\n            // If can't read script, just use metadata\r\n          }\r\n        }\r\n        break;\r\n        \r\n      case 'config':\r\n        // For configs, read JSON content\r\n        content = `Configuration: ${item.name}\r\nType: ${item.type}\r\nPath: ${item.storagePath}`;\r\n        \r\n        if (item.storagePath) {\r\n          try {\r\n            const configContent = await fs.readFile(item.storagePath, 'utf8');\r\n            content += `\\n\\nConfiguration Content:\\n${configContent}`;\r\n          } catch (error) {\r\n            // If can't read config, just use metadata\r\n          }\r\n        }\r\n        break;\r\n        \r\n      default:\r\n        content = `File: ${item.name || 'Unknown'}\r\nType: ${type}/${category}\r\nDescription: ${item.description || 'No description available'}`;\r\n    }\r\n    \r\n    return {\r\n      content,\r\n      sections\r\n    };\r\n  } catch (error) {\r\n    return {\r\n      content: `Error preparing content: ${error.message}`,\r\n      sections: []\r\n    };\r\n  }\r\n}\r\n\r\n/**\r\n * Prepare metadata for OMAI ingestion\r\n */\r\nasync function prepareMetadataForOMAI(result) {\r\n  const { item, type, category, id } = result;\r\n  \r\n  return {\r\n    source: item.storagePath || item.path || `big-book-${type}-${id}`,\r\n    sourceType: mapBigBookTypeToOMAI(type),\r\n    fileType: category,\r\n    tags: getBigBookTags(type, category, item),\r\n    priority: type === 'doc' || type === 'addon' ? 'high' : 'medium',\r\n    processor: 'bigbook-ingestion',\r\n    chunking: type === 'doc' ? 'section' : 'single',\r\n    timestamp: new Date().toISOString(),\r\n    size: item.size || 0,\r\n    relativePath: item.name || `${type}-${id}`,\r\n    bigBookMeta: {\r\n      registryType: type,\r\n      category,\r\n      enabled: item.enabled || false,\r\n      displayName: item.displayName || item.title || item.name,\r\n      route: item.route,\r\n      webPath: item.webPath\r\n    }\r\n  };\r\n}\r\n\r\n/**\r\n * Map Big Book types to OMAI source types\r\n */\r\nfunction mapBigBookTypeToOMAI(type) {\r\n  const mapping = {\r\n    'doc': 'documentation',\r\n    'addon': 'react-component',\r\n    'script': 'code',\r\n    'config': 'json',\r\n    'data': 'general'\r\n  };\r\n  return mapping[type] || 'general';\r\n}\r\n\r\n/**\r\n * Get appropriate tags for Big Book items\r\n */\r\nfunction getBigBookTags(type, category, item) {\r\n  const baseTags = ['BigBook', 'Auto-Ingested'];\r\n  \r\n  switch (type) {\r\n    case 'doc':\r\n      return [...baseTags, 'Documentation', 'Markdown', 'User Guide'];\r\n    case 'addon':\r\n      return [...baseTags, 'Component', 'Frontend', 'React', 'UI', 'Interactive'];\r\n    case 'script':\r\n      return [...baseTags, 'Script', 'Automation', 'Admin Tool'];\r\n    case 'config':\r\n      return [...baseTags, 'Configuration', 'Settings', 'JSON'];\r\n    case 'data':\r\n      return [...baseTags, 'Data', 'Archive', 'Storage'];\r\n    default:\r\n      return [...baseTags, 'General'];\r\n  }\r\n}\r\n\r\n/**\r\n * Big Book Custom Components Registry\r\n * GET /api/bigbook/custom-components-registry\r\n */\r\nrouter.get('/custom-components-registry', authenticate, authorize(['super_admin', 'editor']), async (req, res) => {\r\n  try {\r\n    const fs = require('fs').promises;\r\n    const path = require('path');\r\n    \r\n    const registryPath = path.join(__dirname, '../../front-end/src/config/bigbook-custom-components.json');\r\n    \r\n    try {\r\n      const registryContent = await fs.readFile(registryPath, 'utf8');\r\n      const registry = JSON.parse(registryContent);\r\n      \r\n      res.json({\r\n        success: true,\r\n        ...registry\r\n      });\r\n    } catch (error) {\r\n      // Registry doesn't exist, return empty registry\r\n      res.json({\r\n        success: true,\r\n        components: {},\r\n        routes: {},\r\n        menu: [],\r\n        lastUpdated: null,\r\n        version: \"1.0.0\"\r\n      });\r\n    }\r\n    \r\n  } catch (error) {\r\n    await logToFile('tsx-components.log', `Failed to load custom components registry: ${error.message}`);\r\n    \r\n    res.status(500).json({\r\n      success: false,\r\n      error: error.message\r\n    });\r\n  }\r\n});\r\n\r\n/**\r\n * Big Book Custom Component Installation (Enhanced)\r\n * POST /api/bigbook/install-bigbook-component\r\n */\r\nrouter.post('/install-bigbook-component', authenticate, authorize(['super_admin', 'editor']), async (req, res) => {\r\n  try {\r\n    const { componentInfo, installOptions } = req.body;\r\n    \r\n    if (!componentInfo || !installOptions) {\r\n      return res.status(400).json({\r\n        success: false,\r\n        error: 'Component info and install options are required'\r\n      });\r\n    }\r\n    \r\n    await logToFile('tsx-components.log', `Installing Big Book custom component: ${componentInfo.componentName} by ${req.user?.username || 'unknown'}`);\r\n    \r\n    // Force Big Book-specific settings\r\n    const bigBookInstallOptions = {\r\n      ...installOptions,\r\n      targetDirectory: 'src/components/bigbook/custom',\r\n      registerInRegistry: true // Always register Big Book components\r\n    };\r\n    \r\n    // Install the component using enhanced Big Book function\r\n    const installResult = await installBigBookCustomComponent(componentInfo, bigBookInstallOptions, req.user?.username || 'unknown');\r\n    \r\n    res.json({\r\n      success: true,\r\n      ...installResult\r\n    });\r\n    \r\n  } catch (error) {\r\n    await logToFile('tsx-components.log', `Big Book component installation failed: ${req.body?.componentInfo?.componentName || 'unknown'} - ${error.message}`);\r\n    \r\n    res.status(500).json({\r\n      success: false,\r\n      error: error.message\r\n    });\r\n  }\r\n});\r\n\r\n/**\r\n * Big Book Custom Component Removal (Enhanced)\r\n * DELETE /api/bigbook/remove-bigbook-component\r\n */\r\nrouter.delete('/remove-bigbook-component', authenticate, authorize(['super_admin', 'editor']), async (req, res) => {\r\n  try {\r\n    const { installationResult } = req.body;\r\n    \r\n    if (!installationResult) {\r\n      return res.status(400).json({\r\n        success: false,\r\n        error: 'Installation result is required for removal'\r\n      });\r\n    }\r\n    \r\n    await logToFile('tsx-components.log', `Removing Big Book custom component: ${installationResult.componentName} by ${req.user?.username || 'unknown'}`);\r\n    \r\n    // Remove the component using enhanced Big Book function\r\n    const removalResult = await removeBigBookCustomComponent(installationResult, req.user?.username || 'unknown');\r\n    \r\n    res.json({\r\n      success: true,\r\n      ...removalResult\r\n    });\r\n    \r\n  } catch (error) {\r\n    await logToFile('tsx-components.log', `Big Book component removal failed: ${req.body?.installationResult?.componentName || 'unknown'} - ${error.message}`);\r\n    \r\n    res.status(500).json({\r\n      success: false,\r\n      error: error.message\r\n    });\r\n  }\r\n});\r\n\r\n/**\r\n * TSX Component Parser and Validator\r\n * POST /api/bigbook/parse-tsx-component\r\n */\r\nrouter.post('/parse-tsx-component', authenticate, authorize(['super_admin', 'editor']), async (req, res) => {\r\n  try {\r\n    const { fileName, content } = req.body;\r\n    \r\n    if (!fileName || !content) {\r\n      return res.status(400).json({\r\n        success: false,\r\n        error: 'File name and content are required'\r\n      });\r\n    }\r\n    \r\n    if (!fileName.endsWith('.tsx')) {\r\n      return res.status(400).json({\r\n        success: false,\r\n        error: 'File must be a .tsx file'\r\n      });\r\n    }\r\n    \r\n    await logToFile('tsx-components.log', `Parsing TSX component: ${fileName} by ${req.user?.username || 'unknown'}`);\r\n    \r\n    // Parse component information\r\n    const componentInfo = await parseTSXComponent(fileName, content);\r\n    \r\n    res.json({\r\n      success: true,\r\n      componentInfo\r\n    });\r\n    \r\n  } catch (error) {\r\n    await logToFile('tsx-components.log', `TSX parsing failed: ${req.body?.fileName || 'unknown'} - ${error.message}`);\r\n    \r\n    res.status(500).json({\r\n      success: false,\r\n      error: error.message,\r\n      errors: error.errors || [],\r\n      warnings: error.warnings || []\r\n    });\r\n  }\r\n});\r\n\r\n/**\r\n * TSX Component Installation\r\n * POST /api/bigbook/install-tsx-component\r\n */\r\nrouter.post('/install-tsx-component', authenticate, authorize(['super_admin', 'editor']), async (req, res) => {\r\n  try {\r\n    const { componentInfo, installOptions } = req.body;\r\n    \r\n    if (!componentInfo || !installOptions) {\r\n      return res.status(400).json({\r\n        success: false,\r\n        error: 'Component info and install options are required'\r\n      });\r\n    }\r\n    \r\n    await logToFile('tsx-components.log', `Installing TSX component: ${componentInfo.componentName} by ${req.user?.username || 'unknown'}`);\r\n    \r\n    // Install the component\r\n    const installResult = await installTSXComponent(componentInfo, installOptions, req.user?.username || 'unknown');\r\n    \r\n    res.json({\r\n      success: true,\r\n      ...installResult\r\n    });\r\n    \r\n  } catch (error) {\r\n    await logToFile('tsx-components.log', `TSX installation failed: ${req.body?.componentInfo?.componentName || 'unknown'} - ${error.message}`);\r\n    \r\n    res.status(500).json({\r\n      success: false,\r\n      error: error.message\r\n    });\r\n  }\r\n});\r\n\r\n/**\r\n * TSX Component Removal\r\n * DELETE /api/bigbook/remove-tsx-component\r\n */\r\nrouter.delete('/remove-tsx-component', authenticate, authorize(['super_admin', 'editor']), async (req, res) => {\r\n  try {\r\n    const { installationResult } = req.body;\r\n    \r\n    if (!installationResult) {\r\n      return res.status(400).json({\r\n        success: false,\r\n        error: 'Installation result is required for removal'\r\n      });\r\n    }\r\n    \r\n    await logToFile('tsx-components.log', `Removing TSX component: ${installationResult.componentName} by ${req.user?.username || 'unknown'}`);\r\n    \r\n    // Remove the component\r\n    const removalResult = await removeTSXComponent(installationResult, req.user?.username || 'unknown');\r\n    \r\n    res.json({\r\n      success: true,\r\n      ...removalResult\r\n    });\r\n    \r\n  } catch (error) {\r\n    await logToFile('tsx-components.log', `TSX removal failed: ${req.body?.installationResult?.componentName || 'unknown'} - ${error.message}`);\r\n    \r\n    res.status(500).json({\r\n      success: false,\r\n      error: error.message\r\n    });\r\n  }\r\n});\r\n\r\n/**\r\n * TSX Component Parser Implementation\r\n */\r\nasync function parseTSXComponent(fileName, content) {\r\n  const fs = require('fs').promises;\r\n  const path = require('path');\r\n  \r\n  const componentInfo = {\r\n    fileName,\r\n    componentName: '',\r\n    isDefaultExport: false,\r\n    imports: [],\r\n    content,\r\n    size: content.length,\r\n    isValid: false,\r\n    errors: [],\r\n    warnings: [],\r\n    missingPackages: [],\r\n    hasJSX: false,\r\n    hasHooks: false,\r\n    dependencies: []\r\n  };\r\n  \r\n  try {\r\n    // Enhanced Security Validation\r\n    if (!fileName.endsWith('.tsx')) {\r\n      componentInfo.errors.push('File must have .tsx extension');\r\n      componentInfo.isValid = false;\r\n      return componentInfo;\r\n    }\r\n    \r\n    // Check for malicious patterns\r\n    const dangerousPatterns = [\r\n      /eval\\s*\\(/,\r\n      /Function\\s*\\(/,\r\n      /document\\.write/,\r\n      /innerHTML\\s*=/,\r\n      /outerHTML\\s*=/,\r\n      /dangerouslySetInnerHTML/,\r\n      /window\\s*\\[\\s*['\"`]/,\r\n      /globalThis/,\r\n      /process\\.env/,\r\n      /__dirname/,\r\n      /__filename/,\r\n      /require\\s*\\(/,\r\n      /import\\s*\\(\\s*['\"`]/\r\n    ];\r\n    \r\n    for (const pattern of dangerousPatterns) {\r\n      if (pattern.test(content)) {\r\n        componentInfo.errors.push(`Potentially dangerous code pattern detected: ${pattern.toString()}`);\r\n      }\r\n    }\r\n    \r\n    // Validate file size (max 1MB)\r\n    if (content.length > 1024 * 1024) {\r\n      componentInfo.errors.push('File size too large (max 1MB allowed)');\r\n    }\r\n    \r\n    // Extract component name from file name\r\n    const baseName = path.basename(fileName, '.tsx');\r\n    \r\n    // Convert kebab-case or snake_case to PascalCase for React component name\r\n    const convertToPascalCase = (str) => {\r\n      return str.split(/[-_]/).map(word => \r\n        word.charAt(0).toUpperCase() + word.slice(1).toLowerCase()\r\n      ).join('');\r\n    };\r\n    \r\n    // Get the actual component name that will be used\r\n    const actualComponentName = convertToPascalCase(baseName);\r\n    \r\n    // Validate that the converted component name is valid\r\n    if (!/^[A-Z][A-Za-z0-9]*$/.test(actualComponentName)) {\r\n      componentInfo.errors.push(`Invalid component name \"${baseName}\". Component names must contain only letters, numbers, hyphens, or underscores`);\r\n    }\r\n    \r\n    componentInfo.componentName = actualComponentName;\r\n    \r\n    // Check for JSX content\r\n    componentInfo.hasJSX = /<\\w+/.test(content) || /jsx/.test(content);\r\n    \r\n    // Check for React hooks\r\n    componentInfo.hasHooks = /use[A-Z]\\w*\\s*\\(/.test(content);\r\n    \r\n    // Extract imports\r\n    const importMatches = content.match(/import\\s+.*?from\\s+['\"`]([^'\"`]+)['\"`]/g) || [];\r\n    componentInfo.imports = importMatches.map(match => {\r\n      const moduleMatch = match.match(/from\\s+['\"`]([^'\"`]+)['\"`]/);\r\n      return moduleMatch ? moduleMatch[1] : '';\r\n    }).filter(Boolean);\r\n    \r\n    // Check for default export\r\n    componentInfo.isDefaultExport = /export\\s+default\\s+/.test(content);\r\n    \r\n    // Check for valid React component (check for both original filename and converted name)\r\n    const hasComponentDefinition = new RegExp(`(const|function|class)\\\\s+(${baseName}|${actualComponentName})\\\\s*[=:(<]`).test(content);\r\n    const hasReactImport = /import\\s+.*?React.*?from\\s+['\"`]react['\"`]/.test(content) || \r\n                          /import\\s+React/.test(content);\r\n    \r\n    if (!hasComponentDefinition) {\r\n      componentInfo.warnings.push(`Component definition should match filename. Expected: ${actualComponentName} (converted from ${baseName})`);\r\n    }\r\n    \r\n    if (!hasReactImport && componentInfo.hasJSX) {\r\n      componentInfo.warnings.push('JSX detected but no React import found');\r\n    }\r\n    \r\n    // Validate syntax (basic checks)\r\n    const openBraces = (content.match(/{/g) || []).length;\r\n    const closeBraces = (content.match(/}/g) || []).length;\r\n    \r\n    if (openBraces !== closeBraces) {\r\n      componentInfo.errors.push('Mismatched braces in component');\r\n    }\r\n    \r\n    // Check for common missing packages\r\n    const packageChecks = {\r\n      '@mui/material': /@mui\\/material/.test(content),\r\n      '@mui/icons-material': /@mui\\/icons-material/.test(content),\r\n      'react-router-dom': /react-router-dom/.test(content),\r\n      'axios': /axios/.test(content)\r\n    };\r\n    \r\n    for (const [pkg, isUsed] of Object.entries(packageChecks)) {\r\n      if (isUsed && !componentInfo.imports.includes(pkg)) {\r\n        componentInfo.missingPackages.push(pkg);\r\n      }\r\n    }\r\n    \r\n    // Component is valid if no errors\r\n    componentInfo.isValid = componentInfo.errors.length === 0;\r\n    \r\n    // Extract dependencies\r\n    componentInfo.dependencies = componentInfo.imports.filter(imp => \r\n      !imp.startsWith('.') && !imp.startsWith('/')\r\n    );\r\n    \r\n    return componentInfo;\r\n    \r\n  } catch (error) {\r\n    componentInfo.errors.push(`Parse error: ${error.message}`);\r\n    componentInfo.isValid = false;\r\n    return componentInfo;\r\n  }\r\n}\r\n\r\n/**\r\n * TSX Component Installation Implementation\r\n */\r\nasync function installTSXComponent(componentInfo, installOptions, username) {\r\n  const fs = require('fs').promises;\r\n  const path = require('path');\r\n  const { execSync } = require('child_process');\r\n  \r\n  const frontEndRoot = path.join(__dirname, '../../front-end');\r\n  const targetPath = path.join(frontEndRoot, installOptions.targetDirectory);\r\n  const filePath = path.join(targetPath, componentInfo.fileName);\r\n  \r\n  const result = {\r\n    componentName: componentInfo.componentName,\r\n    installedPath: path.relative(frontEndRoot, filePath),\r\n    packagesInstalled: [],\r\n    registryUpdated: false,\r\n    previewUrl: null,\r\n    backupCreated: null\r\n  };\r\n  \r\n  try {\r\n    // Ensure target directory exists\r\n    await fs.mkdir(targetPath, { recursive: true });\r\n    \r\n    // Check if file already exists\r\n    try {\r\n      await fs.access(filePath);\r\n      if (!installOptions.overwriteExisting) {\r\n        throw new Error(`File already exists: ${componentInfo.fileName}. Enable overwrite to replace.`);\r\n      }\r\n      \r\n      // Create backup\r\n      const backupPath = `${filePath}.backup.${Date.now()}`;\r\n      await fs.copyFile(filePath, backupPath);\r\n      result.backupCreated = path.relative(frontEndRoot, backupPath);\r\n    } catch (error) {\r\n      // File doesn't exist, that's fine\r\n    }\r\n    \r\n    // Write the component file\r\n    await fs.writeFile(filePath, componentInfo.content, 'utf8');\r\n    \r\n    // Install missing packages if requested\r\n    if (installOptions.installMissingPackages && componentInfo.missingPackages.length > 0) {\r\n      try {\r\n        const packagesStr = componentInfo.missingPackages.join(' ');\r\n        execSync(`cd ${frontEndRoot} && npm install ${packagesStr} --legacy-peer-deps`, {\r\n          stdio: 'inherit',\r\n          timeout: 120000 // 2 minutes timeout\r\n        });\r\n        result.packagesInstalled = componentInfo.missingPackages;\r\n      } catch (error) {\r\n        // Package installation failed, but component was still installed\r\n        await logToFile('tsx-components.log', `Package installation failed: ${error.message}`);\r\n      }\r\n    }\r\n    \r\n    // Register in component registry if requested\r\n    if (installOptions.registerInRegistry && componentInfo.isDefaultExport) {\r\n      try {\r\n        await registerComponentInRegistry(componentInfo, result.installedPath);\r\n        result.registryUpdated = true;\r\n      } catch (error) {\r\n        await logToFile('tsx-components.log', `Registry registration failed: ${error.message}`);\r\n      }\r\n    }\r\n    \r\n    // Generate preview URL if requested\r\n    if (installOptions.openPreview) {\r\n      result.previewUrl = `/admin/settings#big-book-registry`;\r\n    }\r\n    \r\n    await logToFile('tsx-components.log', `TSX component installed successfully: ${componentInfo.componentName} by ${username}`);\r\n    \r\n    return result;\r\n    \r\n  } catch (error) {\r\n    // Clean up on failure\r\n    try {\r\n      await fs.unlink(filePath);\r\n    } catch (cleanupError) {\r\n      // Ignore cleanup errors\r\n    }\r\n    \r\n    throw error;\r\n  }\r\n}\r\n\r\n/**\r\n * TSX Component Removal Implementation\r\n */\r\nasync function removeTSXComponent(installationResult, username) {\r\n  const fs = require('fs').promises;\r\n  const path = require('path');\r\n  \r\n  const frontEndRoot = path.join(__dirname, '../../front-end');\r\n  const filePath = path.join(frontEndRoot, installationResult.installedPath);\r\n  \r\n  try {\r\n    // Remove the component file\r\n    await fs.unlink(filePath);\r\n    \r\n    // Restore backup if it exists\r\n    if (installationResult.backupCreated) {\r\n      const backupPath = path.join(frontEndRoot, installationResult.backupCreated);\r\n      try {\r\n        await fs.copyFile(backupPath, filePath);\r\n        await fs.unlink(backupPath);\r\n      } catch (error) {\r\n        await logToFile('tsx-components.log', `Backup restoration failed: ${error.message}`);\r\n      }\r\n    }\r\n    \r\n    // Remove from registry if it was registered\r\n    if (installationResult.registryUpdated) {\r\n      try {\r\n        await unregisterComponentFromRegistry(installationResult.componentName);\r\n      } catch (error) {\r\n        await logToFile('tsx-components.log', `Registry removal failed: ${error.message}`);\r\n      }\r\n    }\r\n    \r\n    await logToFile('tsx-components.log', `TSX component removed successfully: ${installationResult.componentName} by ${username}`);\r\n    \r\n    return {\r\n      componentName: installationResult.componentName,\r\n      removed: true\r\n    };\r\n    \r\n  } catch (error) {\r\n    throw new Error(`Failed to remove component: ${error.message}`);\r\n  }\r\n}\r\n\r\n/**\r\n * Register component in the component registry\r\n */\r\nasync function registerComponentInRegistry(componentInfo, installedPath) {\r\n  const fs = require('fs').promises;\r\n  const path = require('path');\r\n  \r\n  const registryPath = path.join(__dirname, '../../front-end/src/config/component-registry.json');\r\n  \r\n  try {\r\n    let registry = {};\r\n    \r\n    // Try to read existing registry\r\n    try {\r\n      const registryContent = await fs.readFile(registryPath, 'utf8');\r\n      registry = JSON.parse(registryContent);\r\n    } catch (error) {\r\n      // Registry doesn't exist, start with empty object\r\n    }\r\n    \r\n    // Add component to registry\r\n    registry[componentInfo.componentName] = {\r\n      id: componentInfo.componentName,\r\n      name: componentInfo.componentName,\r\n      path: installedPath,\r\n      isDefaultExport: componentInfo.isDefaultExport,\r\n      hasJSX: componentInfo.hasJSX,\r\n      hasHooks: componentInfo.hasHooks,\r\n      dependencies: componentInfo.dependencies,\r\n      installedAt: new Date().toISOString(),\r\n      autoInstalled: true\r\n    };\r\n    \r\n    // Write updated registry\r\n    await fs.writeFile(registryPath, JSON.stringify(registry, null, 2));\r\n    \r\n  } catch (error) {\r\n    throw new Error(`Registry update failed: ${error.message}`);\r\n  }\r\n}\r\n\r\n/**\r\n * Remove component from the component registry\r\n */\r\nasync function unregisterComponentFromRegistry(componentName) {\r\n  const fs = require('fs').promises;\r\n  const path = require('path');\r\n  \r\n  const registryPath = path.join(__dirname, '../../front-end/src/config/component-registry.json');\r\n  \r\n  try {\r\n    const registryContent = await fs.readFile(registryPath, 'utf8');\r\n    const registry = JSON.parse(registryContent);\r\n    \r\n    if (registry[componentName]) {\r\n      delete registry[componentName];\r\n      await fs.writeFile(registryPath, JSON.stringify(registry, null, 2));\r\n    }\r\n    \r\n  } catch (error) {\r\n    throw new Error(`Registry removal failed: ${error.message}`);\r\n  }\r\n}\r\n\r\n/**\r\n * Enhanced TSX Component Installation for Big Book Custom Components\r\n */\r\nasync function installBigBookCustomComponent(componentInfo, installOptions, username) {\r\n  const fs = require('fs').promises;\r\n  const path = require('path');\r\n  const { execSync } = require('child_process');\r\n  \r\n  const frontEndRoot = path.join(__dirname, '../../front-end');\r\n  \r\n  // Force Big Book custom components directory\r\n  const bigBookCustomDir = 'src/components/bigbook/custom';\r\n  const targetPath = path.join(frontEndRoot, bigBookCustomDir);\r\n  const filePath = path.join(targetPath, componentInfo.fileName);\r\n  \r\n  // Generate component route name (kebab-case)\r\n  const routeName = componentInfo.componentName\r\n    .replace(/([A-Z])/g, '-$1')\r\n    .toLowerCase()\r\n    .replace(/^-/, '');\r\n  \r\n  const displayName = componentInfo.componentName\r\n    .replace(/([A-Z])/g, ' $1')\r\n    .trim();\r\n  \r\n  const result = {\r\n    componentName: componentInfo.componentName,\r\n    installedPath: path.relative(frontEndRoot, filePath),\r\n    route: `/bigbook/component/${routeName}`,\r\n    displayName: displayName,\r\n    packagesInstalled: [],\r\n    registryUpdated: false,\r\n    menuUpdated: false,\r\n    previewUrl: null,\r\n    backupCreated: null\r\n  };\r\n  \r\n  try {\r\n    // Ensure Big Book custom components directory exists\r\n    await fs.mkdir(targetPath, { recursive: true });\r\n    \r\n    // Check if file already exists\r\n    try {\r\n      await fs.access(filePath);\r\n      if (!installOptions.overwriteExisting) {\r\n        throw new Error(`Component already exists: ${componentInfo.fileName}. Enable overwrite to replace.`);\r\n      }\r\n      \r\n      // Create backup\r\n      const backupPath = `${filePath}.backup.${Date.now()}`;\r\n      await fs.copyFile(filePath, backupPath);\r\n      result.backupCreated = path.relative(frontEndRoot, backupPath);\r\n    } catch (error) {\r\n      // File doesn't exist, that's fine\r\n    }\r\n    \r\n    // Write the component file\r\n    await fs.writeFile(filePath, componentInfo.content, 'utf8');\r\n    \r\n    // Install missing packages if requested\r\n    if (installOptions.installMissingPackages && componentInfo.missingPackages.length > 0) {\r\n      try {\r\n        const packagesStr = componentInfo.missingPackages.join(' ');\r\n        execSync(`cd ${frontEndRoot} && npm install ${packagesStr} --legacy-peer-deps`, {\r\n          stdio: 'inherit',\r\n          timeout: 120000 // 2 minutes timeout\r\n        });\r\n        result.packagesInstalled = componentInfo.missingPackages;\r\n      } catch (error) {\r\n        // Package installation failed, but component was still installed\r\n        await logToFile('tsx-components.log', `Package installation failed: ${error.message}`);\r\n      }\r\n    }\r\n    \r\n    // Register in Big Book custom component registry\r\n    if (installOptions.registerInRegistry && componentInfo.isDefaultExport) {\r\n      try {\r\n        await registerBigBookCustomComponent(componentInfo, result);\r\n        result.registryUpdated = true;\r\n        result.menuUpdated = true;\r\n      } catch (error) {\r\n        await logToFile('tsx-components.log', `Big Book registry registration failed: ${error.message}`);\r\n      }\r\n    }\r\n    \r\n    // Generate preview URL for Big Book custom component\r\n    if (installOptions.openPreview) {\r\n      result.previewUrl = result.route;\r\n    }\r\n    \r\n    await logToFile('tsx-components.log', `Big Book custom component installed successfully: ${componentInfo.componentName} by ${username}`);\r\n    \r\n    return result;\r\n    \r\n  } catch (error) {\r\n    // Clean up on failure\r\n    try {\r\n      await fs.unlink(filePath);\r\n    } catch (cleanupError) {\r\n      // Ignore cleanup errors\r\n    }\r\n    \r\n    throw error;\r\n  }\r\n}\r\n\r\n/**\r\n * Register component in Big Book custom component registry\r\n */\r\nasync function registerBigBookCustomComponent(componentInfo, installResult) {\r\n  const fs = require('fs').promises;\r\n  const path = require('path');\r\n  \r\n  const registryPath = path.join(__dirname, '../../front-end/src/config/bigbook-custom-components.json');\r\n  \r\n  try {\r\n    let registry = {\r\n      components: {},\r\n      routes: {},\r\n      menu: [],\r\n      lastUpdated: null,\r\n      version: \"1.0.0\"\r\n    };\r\n    \r\n    // Try to read existing registry\r\n    try {\r\n      const registryContent = await fs.readFile(registryPath, 'utf8');\r\n      registry = JSON.parse(registryContent);\r\n    } catch (error) {\r\n      // Registry doesn't exist, use default structure\r\n    }\r\n    \r\n    // Add component to registry\r\n    const componentData = {\r\n      id: componentInfo.componentName,\r\n      name: componentInfo.componentName,\r\n      path: installResult.installedPath,\r\n      route: installResult.route,\r\n      displayName: installResult.displayName,\r\n      description: `Custom Big Book component: ${installResult.displayName}`,\r\n      installedAt: new Date().toISOString(),\r\n      autoInstalled: true,\r\n      isDefaultExport: componentInfo.isDefaultExport,\r\n      hasJSX: componentInfo.hasJSX,\r\n      hasHooks: componentInfo.hasHooks,\r\n      dependencies: componentInfo.dependencies\r\n    };\r\n    \r\n    registry.components[componentInfo.componentName] = componentData;\r\n    registry.routes[installResult.route] = componentInfo.componentName;\r\n    \r\n    // Add to menu if not already present\r\n    const existingMenuIndex = registry.menu.findIndex(item => item.id === componentInfo.componentName);\r\n    const menuItem = {\r\n      id: componentInfo.componentName,\r\n      name: componentInfo.componentName,\r\n      displayName: installResult.displayName,\r\n      route: installResult.route,\r\n      icon: 'Extension'\r\n    };\r\n    \r\n    if (existingMenuIndex >= 0) {\r\n      registry.menu[existingMenuIndex] = menuItem;\r\n    } else {\r\n      registry.menu.push(menuItem);\r\n    }\r\n    \r\n    // Sort menu items by display name\r\n    registry.menu.sort((a, b) => a.displayName.localeCompare(b.displayName));\r\n    \r\n    registry.lastUpdated = new Date().toISOString();\r\n    \r\n    // Write updated registry\r\n    await fs.writeFile(registryPath, JSON.stringify(registry, null, 2));\r\n    \r\n  } catch (error) {\r\n    throw new Error(`Big Book registry update failed: ${error.message}`);\r\n  }\r\n}\r\n\r\n/**\r\n * Remove component from Big Book custom component registry\r\n */\r\nasync function unregisterBigBookCustomComponent(componentName) {\r\n  const fs = require('fs').promises;\r\n  const path = require('path');\r\n  \r\n  const registryPath = path.join(__dirname, '../../front-end/src/config/bigbook-custom-components.json');\r\n  \r\n  try {\r\n    const registryContent = await fs.readFile(registryPath, 'utf8');\r\n    const registry = JSON.parse(registryContent);\r\n    \r\n    if (registry.components[componentName]) {\r\n      const component = registry.components[componentName];\r\n      \r\n      // Remove from components\r\n      delete registry.components[componentName];\r\n      \r\n      // Remove from routes\r\n      if (component.route && registry.routes[component.route]) {\r\n        delete registry.routes[component.route];\r\n      }\r\n      \r\n      // Remove from menu\r\n      registry.menu = registry.menu.filter(item => item.id !== componentName);\r\n      \r\n      registry.lastUpdated = new Date().toISOString();\r\n      \r\n      await fs.writeFile(registryPath, JSON.stringify(registry, null, 2));\r\n    }\r\n    \r\n  } catch (error) {\r\n    throw new Error(`Big Book registry removal failed: ${error.message}`);\r\n  }\r\n}\r\n\r\n/**\r\n * Enhanced TSX Component Removal for Big Book Custom Components\r\n */\r\nasync function removeBigBookCustomComponent(installationResult, username) {\r\n  const fs = require('fs').promises;\r\n  const path = require('path');\r\n  \r\n  const frontEndRoot = path.join(__dirname, '../../front-end');\r\n  const filePath = path.join(frontEndRoot, installationResult.installedPath);\r\n  \r\n  try {\r\n    // Remove the component file\r\n    await fs.unlink(filePath);\r\n    \r\n    // Restore backup if it exists\r\n    if (installationResult.backupCreated) {\r\n      const backupPath = path.join(frontEndRoot, installationResult.backupCreated);\r\n      try {\r\n        await fs.copyFile(backupPath, filePath);\r\n        await fs.unlink(backupPath);\r\n      } catch (error) {\r\n        await logToFile('tsx-components.log', `Backup restoration failed: ${error.message}`);\r\n      }\r\n    }\r\n    \r\n    // Remove from Big Book registry if it was registered\r\n    if (installationResult.registryUpdated) {\r\n      try {\r\n        await unregisterBigBookCustomComponent(installationResult.componentName);\r\n      } catch (error) {\r\n        await logToFile('tsx-components.log', `Big Book registry removal failed: ${error.message}`);\r\n      }\r\n    }\r\n    \r\n    await logToFile('tsx-components.log', `Big Book custom component removed successfully: ${installationResult.componentName} by ${username}`);\r\n    \r\n    return {\r\n      componentName: installationResult.componentName,\r\n      removed: true,\r\n      menuUpdated: true\r\n    };\r\n    \r\n  } catch (error) {\r\n    throw new Error(`Failed to remove Big Book custom component: ${error.message}`);\r\n  }\r\n}\r\n\r\nmodule.exports = router; "
    },
    "complexity": {
      "totalLines": 3687,
      "codeLines": 2762,
      "commentLines": 377,
      "commentRatio": 0.1201019432940427,
      "averageLineLength": 34.96145269194011
    },
    "lastAnalyzed": "2025-07-28T07:20:00.419Z"
  },
  "contentHash": "1729956fbe0e084f4698e677734b51eccd9b5d82d4f67cb0e3feb73600999d87",
  "discoveredAt": "2025-07-28T07:20:00.420Z"
}